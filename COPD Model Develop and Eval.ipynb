{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fW3OF8jAYb8P"},"outputs":[],"source":["import os\n","import sqlite3\n","import pandas as pd\n","from google.colab import drive\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRovg-gxcSeY","executionInfo":{"status":"ok","timestamp":1652926577224,"user_tz":420,"elapsed":121966,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"ac007c82-46ce-417e-c492-50339fee58d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Set root, project, and working directories\n","rd = '/content/drive'\n","ad = '/Shareddrives/Hasenstab Lab/Data/COPDGene'\n","wd = '/univariate_histograms'\n","hd = '/histograms'\n","\n","drive.mount(rd, force_remount = True)\n","\n","sf = '/19000101'\n","cases = os.listdir(f'{rd}{ad}{hd}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_fRKbhxCx8V"},"outputs":[],"source":["# Change directory\n","os.chdir(f'{rd}{ad}{wd}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJrJIYNtC0Rh"},"outputs":[],"source":["# Connect to existing database\n","db_name = 'univariate_histograms'\n","conn = sqlite3.connect(db_name)\n","crsr = conn.cursor()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33yePRo0_byG","executionInfo":{"status":"ok","timestamp":1652926619738,"user_tz":420,"elapsed":7327,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"a6fad924-20c2-47bc-d46b-21c49367e880"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (2133) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}],"source":["insp_df = pd.read_csv('insp_copd_merge_demo.csv')\n","exp_df = pd.read_csv('exp_copd_merge.csv')\n","adm_df = pd.read_csv('adm_copd_merge.csv')"]},{"cell_type":"code","source":["len(insp_df)\n","#gold_stage = -2 need to remove, we can leave in -1 should fall under gold 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UStQP6VizTx0","executionInfo":{"status":"ok","timestamp":1652926622363,"user_tz":420,"elapsed":127,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"d4ac2884-d54b-44d0-a84c-3cd5d312f38c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8995"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"h5mdqMyFwx72"},"source":["#Splitting Biographical Information"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1652926625079,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"KqzNTEw0xIQq","outputId":"fcb98320-7c67-4073-d2a1-9cf6504e6270"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unnamed: 0\n","Unnamed: 0.1\n","idx\n","-1500\n","-1499\n","-1498\n","-1497\n","-1496\n","-1495\n","-1494\n","-1493\n","-1492\n","-1491\n","-1490\n","-1489\n","-1488\n","-1487\n","-1486\n","-1485\n","-1484\n","-1483\n","-1482\n","-1481\n","-1480\n","-1479\n","-1478\n","-1477\n","-1476\n","-1475\n","-1474\n","-1473\n","-1472\n","-1471\n","-1470\n","-1469\n","-1468\n","-1467\n","-1466\n","-1465\n","-1464\n","-1463\n","-1462\n","-1461\n","-1460\n","-1459\n","-1458\n","-1457\n","-1456\n","-1455\n","-1454\n","-1453\n","-1452\n","-1451\n","-1450\n","-1449\n","-1448\n","-1447\n","-1446\n","-1445\n","-1444\n","-1443\n","-1442\n","-1441\n","-1440\n","-1439\n","-1438\n","-1437\n","-1436\n","-1435\n","-1434\n","-1433\n","-1432\n","-1431\n","-1430\n","-1429\n","-1428\n","-1427\n","-1426\n","-1425\n","-1424\n","-1423\n","-1422\n","-1421\n","-1420\n","-1419\n","-1418\n","-1417\n","-1416\n","-1415\n","-1414\n","-1413\n","-1412\n","-1411\n","-1410\n","-1409\n","-1408\n","-1407\n","-1406\n","-1405\n","-1404\n","-1403\n","-1402\n","-1401\n","-1400\n","-1399\n","-1398\n","-1397\n","-1396\n","-1395\n","-1394\n","-1393\n","-1392\n","-1391\n","-1390\n","-1389\n","-1388\n","-1387\n","-1386\n","-1385\n","-1384\n","-1383\n","-1382\n","-1381\n","-1380\n","-1379\n","-1378\n","-1377\n","-1376\n","-1375\n","-1374\n","-1373\n","-1372\n","-1371\n","-1370\n","-1369\n","-1368\n","-1367\n","-1366\n","-1365\n","-1364\n","-1363\n","-1362\n","-1361\n","-1360\n","-1359\n","-1358\n","-1357\n","-1356\n","-1355\n","-1354\n","-1353\n","-1352\n","-1351\n","-1350\n","-1349\n","-1348\n","-1347\n","-1346\n","-1345\n","-1344\n","-1343\n","-1342\n","-1341\n","-1340\n","-1339\n","-1338\n","-1337\n","-1336\n","-1335\n","-1334\n","-1333\n","-1332\n","-1331\n","-1330\n","-1329\n","-1328\n","-1327\n","-1326\n","-1325\n","-1324\n","-1323\n","-1322\n","-1321\n","-1320\n","-1319\n","-1318\n","-1317\n","-1316\n","-1315\n","-1314\n","-1313\n","-1312\n","-1311\n","-1310\n","-1309\n","-1308\n","-1307\n","-1306\n","-1305\n","-1304\n","-1303\n","-1302\n","-1301\n","-1300\n","-1299\n","-1298\n","-1297\n","-1296\n","-1295\n","-1294\n","-1293\n","-1292\n","-1291\n","-1290\n","-1289\n","-1288\n","-1287\n","-1286\n","-1285\n","-1284\n","-1283\n","-1282\n","-1281\n","-1280\n","-1279\n","-1278\n","-1277\n","-1276\n","-1275\n","-1274\n","-1273\n","-1272\n","-1271\n","-1270\n","-1269\n","-1268\n","-1267\n","-1266\n","-1265\n","-1264\n","-1263\n","-1262\n","-1261\n","-1260\n","-1259\n","-1258\n","-1257\n","-1256\n","-1255\n","-1254\n","-1253\n","-1252\n","-1251\n","-1250\n","-1249\n","-1248\n","-1247\n","-1246\n","-1245\n","-1244\n","-1243\n","-1242\n","-1241\n","-1240\n","-1239\n","-1238\n","-1237\n","-1236\n","-1235\n","-1234\n","-1233\n","-1232\n","-1231\n","-1230\n","-1229\n","-1228\n","-1227\n","-1226\n","-1225\n","-1224\n","-1223\n","-1222\n","-1221\n","-1220\n","-1219\n","-1218\n","-1217\n","-1216\n","-1215\n","-1214\n","-1213\n","-1212\n","-1211\n","-1210\n","-1209\n","-1208\n","-1207\n","-1206\n","-1205\n","-1204\n","-1203\n","-1202\n","-1201\n","-1200\n","-1199\n","-1198\n","-1197\n","-1196\n","-1195\n","-1194\n","-1193\n","-1192\n","-1191\n","-1190\n","-1189\n","-1188\n","-1187\n","-1186\n","-1185\n","-1184\n","-1183\n","-1182\n","-1181\n","-1180\n","-1179\n","-1178\n","-1177\n","-1176\n","-1175\n","-1174\n","-1173\n","-1172\n","-1171\n","-1170\n","-1169\n","-1168\n","-1167\n","-1166\n","-1165\n","-1164\n","-1163\n","-1162\n","-1161\n","-1160\n","-1159\n","-1158\n","-1157\n","-1156\n","-1155\n","-1154\n","-1153\n","-1152\n","-1151\n","-1150\n","-1149\n","-1148\n","-1147\n","-1146\n","-1145\n","-1144\n","-1143\n","-1142\n","-1141\n","-1140\n","-1139\n","-1138\n","-1137\n","-1136\n","-1135\n","-1134\n","-1133\n","-1132\n","-1131\n","-1130\n","-1129\n","-1128\n","-1127\n","-1126\n","-1125\n","-1124\n","-1123\n","-1122\n","-1121\n","-1120\n","-1119\n","-1118\n","-1117\n","-1116\n","-1115\n","-1114\n","-1113\n","-1112\n","-1111\n","-1110\n","-1109\n","-1108\n","-1107\n","-1106\n","-1105\n","-1104\n","-1103\n","-1102\n","-1101\n","-1100\n","-1099\n","-1098\n","-1097\n","-1096\n","-1095\n","-1094\n","-1093\n","-1092\n","-1091\n","-1090\n","-1089\n","-1088\n","-1087\n","-1086\n","-1085\n","-1084\n","-1083\n","-1082\n","-1081\n","-1080\n","-1079\n","-1078\n","-1077\n","-1076\n","-1075\n","-1074\n","-1073\n","-1072\n","-1071\n","-1070\n","-1069\n","-1068\n","-1067\n","-1066\n","-1065\n","-1064\n","-1063\n","-1062\n","-1061\n","-1060\n","-1059\n","-1058\n","-1057\n","-1056\n","-1055\n","-1054\n","-1053\n","-1052\n","-1051\n","-1050\n","-1049\n","-1048\n","-1047\n","-1046\n","-1045\n","-1044\n","-1043\n","-1042\n","-1041\n","-1040\n","-1039\n","-1038\n","-1037\n","-1036\n","-1035\n","-1034\n","-1033\n","-1032\n","-1031\n","-1030\n","-1029\n","-1028\n","-1027\n","-1026\n","-1025\n","-1024\n","-1023\n","-1022\n","-1021\n","-1020\n","-1019\n","-1018\n","-1017\n","-1016\n","-1015\n","-1014\n","-1013\n","-1012\n","-1011\n","-1010\n","-1009\n","-1008\n","-1007\n","-1006\n","-1005\n","-1004\n","-1003\n","-1002\n","-1001\n","-1000\n","-999\n","-998\n","-997\n","-996\n","-995\n","-994\n","-993\n","-992\n","-991\n","-990\n","-989\n","-988\n","-987\n","-986\n","-985\n","-984\n","-983\n","-982\n","-981\n","-980\n","-979\n","-978\n","-977\n","-976\n","-975\n","-974\n","-973\n","-972\n","-971\n","-970\n","-969\n","-968\n","-967\n","-966\n","-965\n","-964\n","-963\n","-962\n","-961\n","-960\n","-959\n","-958\n","-957\n","-956\n","-955\n","-954\n","-953\n","-952\n","-951\n","-950\n","-949\n","-948\n","-947\n","-946\n","-945\n","-944\n","-943\n","-942\n","-941\n","-940\n","-939\n","-938\n","-937\n","-936\n","-935\n","-934\n","-933\n","-932\n","-931\n","-930\n","-929\n","-928\n","-927\n","-926\n","-925\n","-924\n","-923\n","-922\n","-921\n","-920\n","-919\n","-918\n","-917\n","-916\n","-915\n","-914\n","-913\n","-912\n","-911\n","-910\n","-909\n","-908\n","-907\n","-906\n","-905\n","-904\n","-903\n","-902\n","-901\n","-900\n","-899\n","-898\n","-897\n","-896\n","-895\n","-894\n","-893\n","-892\n","-891\n","-890\n","-889\n","-888\n","-887\n","-886\n","-885\n","-884\n","-883\n","-882\n","-881\n","-880\n","-879\n","-878\n","-877\n","-876\n","-875\n","-874\n","-873\n","-872\n","-871\n","-870\n","-869\n","-868\n","-867\n","-866\n","-865\n","-864\n","-863\n","-862\n","-861\n","-860\n","-859\n","-858\n","-857\n","-856\n","-855\n","-854\n","-853\n","-852\n","-851\n","-850\n","-849\n","-848\n","-847\n","-846\n","-845\n","-844\n","-843\n","-842\n","-841\n","-840\n","-839\n","-838\n","-837\n","-836\n","-835\n","-834\n","-833\n","-832\n","-831\n","-830\n","-829\n","-828\n","-827\n","-826\n","-825\n","-824\n","-823\n","-822\n","-821\n","-820\n","-819\n","-818\n","-817\n","-816\n","-815\n","-814\n","-813\n","-812\n","-811\n","-810\n","-809\n","-808\n","-807\n","-806\n","-805\n","-804\n","-803\n","-802\n","-801\n","-800\n","-799\n","-798\n","-797\n","-796\n","-795\n","-794\n","-793\n","-792\n","-791\n","-790\n","-789\n","-788\n","-787\n","-786\n","-785\n","-784\n","-783\n","-782\n","-781\n","-780\n","-779\n","-778\n","-777\n","-776\n","-775\n","-774\n","-773\n","-772\n","-771\n","-770\n","-769\n","-768\n","-767\n","-766\n","-765\n","-764\n","-763\n","-762\n","-761\n","-760\n","-759\n","-758\n","-757\n","-756\n","-755\n","-754\n","-753\n","-752\n","-751\n","-750\n","-749\n","-748\n","-747\n","-746\n","-745\n","-744\n","-743\n","-742\n","-741\n","-740\n","-739\n","-738\n","-737\n","-736\n","-735\n","-734\n","-733\n","-732\n","-731\n","-730\n","-729\n","-728\n","-727\n","-726\n","-725\n","-724\n","-723\n","-722\n","-721\n","-720\n","-719\n","-718\n","-717\n","-716\n","-715\n","-714\n","-713\n","-712\n","-711\n","-710\n","-709\n","-708\n","-707\n","-706\n","-705\n","-704\n","-703\n","-702\n","-701\n","-700\n","-699\n","-698\n","-697\n","-696\n","-695\n","-694\n","-693\n","-692\n","-691\n","-690\n","-689\n","-688\n","-687\n","-686\n","-685\n","-684\n","-683\n","-682\n","-681\n","-680\n","-679\n","-678\n","-677\n","-676\n","-675\n","-674\n","-673\n","-672\n","-671\n","-670\n","-669\n","-668\n","-667\n","-666\n","-665\n","-664\n","-663\n","-662\n","-661\n","-660\n","-659\n","-658\n","-657\n","-656\n","-655\n","-654\n","-653\n","-652\n","-651\n","-650\n","-649\n","-648\n","-647\n","-646\n","-645\n","-644\n","-643\n","-642\n","-641\n","-640\n","-639\n","-638\n","-637\n","-636\n","-635\n","-634\n","-633\n","-632\n","-631\n","-630\n","-629\n","-628\n","-627\n","-626\n","-625\n","-624\n","-623\n","-622\n","-621\n","-620\n","-619\n","-618\n","-617\n","-616\n","-615\n","-614\n","-613\n","-612\n","-611\n","-610\n","-609\n","-608\n","-607\n","-606\n","-605\n","-604\n","-603\n","-602\n","-601\n","-600\n","-599\n","-598\n","-597\n","-596\n","-595\n","-594\n","-593\n","-592\n","-591\n","-590\n","-589\n","-588\n","-587\n","-586\n","-585\n","-584\n","-583\n","-582\n","-581\n","-580\n","-579\n","-578\n","-577\n","-576\n","-575\n","-574\n","-573\n","-572\n","-571\n","-570\n","-569\n","-568\n","-567\n","-566\n","-565\n","-564\n","-563\n","-562\n","-561\n","-560\n","-559\n","-558\n","-557\n","-556\n","-555\n","-554\n","-553\n","-552\n","-551\n","-550\n","-549\n","-548\n","-547\n","-546\n","-545\n","-544\n","-543\n","-542\n","-541\n","-540\n","-539\n","-538\n","-537\n","-536\n","-535\n","-534\n","-533\n","-532\n","-531\n","-530\n","-529\n","-528\n","-527\n","-526\n","-525\n","-524\n","-523\n","-522\n","-521\n","-520\n","-519\n","-518\n","-517\n","-516\n","-515\n","-514\n","-513\n","-512\n","-511\n","-510\n","-509\n","-508\n","-507\n","-506\n","-505\n","-504\n","-503\n","-502\n","-501\n","-500\n","-499\n","-498\n","-497\n","-496\n","-495\n","-494\n","-493\n","-492\n","-491\n","-490\n","-489\n","-488\n","-487\n","-486\n","-485\n","-484\n","-483\n","-482\n","-481\n","-480\n","-479\n","-478\n","-477\n","-476\n","-475\n","-474\n","-473\n","-472\n","-471\n","-470\n","-469\n","-468\n","-467\n","-466\n","-465\n","-464\n","-463\n","-462\n","-461\n","-460\n","-459\n","-458\n","-457\n","-456\n","-455\n","-454\n","-453\n","-452\n","-451\n","-450\n","-449\n","-448\n","-447\n","-446\n","-445\n","-444\n","-443\n","-442\n","-441\n","-440\n","-439\n","-438\n","-437\n","-436\n","-435\n","-434\n","-433\n","-432\n","-431\n","-430\n","-429\n","-428\n","-427\n","-426\n","-425\n","-424\n","-423\n","-422\n","-421\n","-420\n","-419\n","-418\n","-417\n","-416\n","-415\n","-414\n","-413\n","-412\n","-411\n","-410\n","-409\n","-408\n","-407\n","-406\n","-405\n","-404\n","-403\n","-402\n","-401\n","-400\n","-399\n","-398\n","-397\n","-396\n","-395\n","-394\n","-393\n","-392\n","-391\n","-390\n","-389\n","-388\n","-387\n","-386\n","-385\n","-384\n","-383\n","-382\n","-381\n","-380\n","-379\n","-378\n","-377\n","-376\n","-375\n","-374\n","-373\n","-372\n","-371\n","-370\n","-369\n","-368\n","-367\n","-366\n","-365\n","-364\n","-363\n","-362\n","-361\n","-360\n","-359\n","-358\n","-357\n","-356\n","-355\n","-354\n","-353\n","-352\n","-351\n","-350\n","-349\n","-348\n","-347\n","-346\n","-345\n","-344\n","-343\n","-342\n","-341\n","-340\n","-339\n","-338\n","-337\n","-336\n","-335\n","-334\n","-333\n","-332\n","-331\n","-330\n","-329\n","-328\n","-327\n","-326\n","-325\n","-324\n","-323\n","-322\n","-321\n","-320\n","-319\n","-318\n","-317\n","-316\n","-315\n","-314\n","-313\n","-312\n","-311\n","-310\n","-309\n","-308\n","-307\n","-306\n","-305\n","-304\n","-303\n","-302\n","-301\n","-300\n","-299\n","-298\n","-297\n","-296\n","-295\n","-294\n","-293\n","-292\n","-291\n","-290\n","-289\n","-288\n","-287\n","-286\n","-285\n","-284\n","-283\n","-282\n","-281\n","-280\n","-279\n","-278\n","-277\n","-276\n","-275\n","-274\n","-273\n","-272\n","-271\n","-270\n","-269\n","-268\n","-267\n","-266\n","-265\n","-264\n","-263\n","-262\n","-261\n","-260\n","-259\n","-258\n","-257\n","-256\n","-255\n","-254\n","-253\n","-252\n","-251\n","-250\n","-249\n","-248\n","-247\n","-246\n","-245\n","-244\n","-243\n","-242\n","-241\n","-240\n","-239\n","-238\n","-237\n","-236\n","-235\n","-234\n","-233\n","-232\n","-231\n","-230\n","-229\n","-228\n","-227\n","-226\n","-225\n","-224\n","-223\n","-222\n","-221\n","-220\n","-219\n","-218\n","-217\n","-216\n","-215\n","-214\n","-213\n","-212\n","-211\n","-210\n","-209\n","-208\n","-207\n","-206\n","-205\n","-204\n","-203\n","-202\n","-201\n","-200\n","-199\n","-198\n","-197\n","-196\n","-195\n","-194\n","-193\n","-192\n","-191\n","-190\n","-189\n","-188\n","-187\n","-186\n","-185\n","-184\n","-183\n","-182\n","-181\n","-180\n","-179\n","-178\n","-177\n","-176\n","-175\n","-174\n","-173\n","-172\n","-171\n","-170\n","-169\n","-168\n","-167\n","-166\n","-165\n","-164\n","-163\n","-162\n","-161\n","-160\n","-159\n","-158\n","-157\n","-156\n","-155\n","-154\n","-153\n","-152\n","-151\n","-150\n","-149\n","-148\n","-147\n","-146\n","-145\n","-144\n","-143\n","-142\n","-141\n","-140\n","-139\n","-138\n","-137\n","-136\n","-135\n","-134\n","-133\n","-132\n","-131\n","-130\n","-129\n","-128\n","-127\n","-126\n","-125\n","-124\n","-123\n","-122\n","-121\n","-120\n","-119\n","-118\n","-117\n","-116\n","-115\n","-114\n","-113\n","-112\n","-111\n","-110\n","-109\n","-108\n","-107\n","-106\n","-105\n","-104\n","-103\n","-102\n","-101\n","-100\n","-99\n","-98\n","-97\n","-96\n","-95\n","-94\n","-93\n","-92\n","-91\n","-90\n","-89\n","-88\n","-87\n","-86\n","-85\n","-84\n","-83\n","-82\n","-81\n","-80\n","-79\n","-78\n","-77\n","-76\n","-75\n","-74\n","-73\n","-72\n","-71\n","-70\n","-69\n","-68\n","-67\n","-66\n","-65\n","-64\n","-63\n","-62\n","-61\n","-60\n","-59\n","-58\n","-57\n","-56\n","-55\n","-54\n","-53\n","-52\n","-51\n","-50\n","-49\n","-48\n","-47\n","-46\n","-45\n","-44\n","-43\n","-42\n","-41\n","-40\n","-39\n","-38\n","-37\n","-36\n","-35\n","-34\n","-33\n","-32\n","-31\n","-30\n","-29\n","-28\n","-27\n","-26\n","-25\n","-24\n","-23\n","-22\n","-21\n","-20\n","-19\n","-18\n","-17\n","-16\n","-15\n","-14\n","-13\n","-12\n","-11\n","-10\n","-9\n","-8\n","-7\n","-6\n","-5\n","-4\n","-3\n","-2\n","-1\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","Unnamed: 0.1.1\n","Unnamed: 0_x\n","sid\n","FEV1_utah_x\n","FVC_utah_x\n","FEV1pp_utah_x\n","Unnamed: 0_y\n","cohort\n","ccenter\n","visitnum\n","shortterm_flag\n","Phase_study\n","Visit_Year\n","Visit_Date\n","days_since_baseline\n","years_from_baseline\n","years_since_last_visit\n","gender\n","race\n","ethnic\n","maritalstatus\n","EverSmokedCig\n","smoking_status\n","ExclusionaryDisease\n","age_baseline\n","age_visit\n","Age_Enroll\n","finalgold_baseline\n","subgroup2019\n","visit_type\n","Exclude_LungTrans_LVRS\n","Limited_form_flag\n","Blood_Other_Use\n","safety_actions_spiro\n","safety_actions_albut\n","safety_actions_6mw\n","safety_actions_sit_stand\n","postcovid_visit_covid_test\n","Height_CM\n","Weight_KG\n","sysBP\n","diasBP\n","sysBP_2\n","diasBP_2\n","sysBP_3\n","diasBP_3\n","Waist_CM\n","Arm_Span_CM\n","HR\n","O2_Hours_Day\n","O2_Therapy\n","O2_Years\n","Resting_SaO2\n","BMI\n","O2use_rest\n","O2use_exercise\n","O2use_sleep\n","o2_rest\n","o2_activity\n","postcovid_visit_6mw\n","attempted_6mw\n","mask_worn_during_6mw\n","O2_suppl_6MW\n","distwalked\n","Walk_Course\n","walk_course_changed\n","Walk_Limit\n","SaO2_EndWalk\n","SaO2_1_Min_Post\n","HR_EndWalk\n","HR_1_Min_Post\n","WalkSymp_BackPain\n","WalkSymp_JointPain\n","WalkSymp_Legs_Fatigue\n","WalkSymp_ShortnessBreath\n","HealthStatus\n","CancerLung\n","CancerBreast\n","CancerProstate\n","CancerColon\n","SkinCancer\n","Melanoma\n","CancerBladder\n","CancerKidney\n","CancerUterine\n","CancerThroatMouth\n","CancerOvarian\n","CancerLeukemia\n","CancerPancreatic\n","CancerLymphoma\n","CancerOther\n","otherca_specify\n","Pneumothorax\n","Angina\n","AFib\n","CongestHeartFail\n","CoronaryArtery\n","Diabetes\n","HighBloodPres\n","HighCholest\n","HeartAttack\n","BloodClots\n","MacularDegen\n","PeriphVascular\n","Stroke\n","TIA\n","CognitiveDisorder\n","Anemia\n","GastroEsophReflx\n","KidneyDisease\n","LiverDisease\n","StomachUlcers\n","CompressFracBack\n","ConnectiveTissueDz\n","Gout\n","HipFracture\n","OsteoArth\n","Osteoporosis\n","RheumArth\n","Pulm_Rehab_slv\n","Pulm_Rehab_Yr\n","Recent_Exercise\n","Exercise_Number\n","Exercise_Minutes\n","StiffPainLimitWk\n","StiffPainBack\n","LimitWalkMost\n","CABG\n","Angioplasty\n","Alpha1Test\n","PhenoGenotype\n","PainfulJoints\n","LowerBackPain\n","Weight_Loss\n","Weight_Loss_amount\n","PainJointType_Shoulder\n","PainJointType_Elbow\n","PainJointType_Wrist\n","PainJointType_Hip\n","PainJointType_Knee\n","PainJointType_Foot\n","cancerlung_slv\n","cancerbreast_slv\n","cancerprostate_slv\n","cancercolon_slv\n","cancerbladder_slv\n","pneumothorax_slv\n","angina_slv\n","congestheartfail_slv\n","coronaryartery_slv\n","highbloodpres_slv\n","highcholest_slv\n","heartattack_slv\n","cabg_slv\n","angioplasty_slv\n","bloodclots_slv\n","maculardegen_slv\n","periphvascular_slv\n","stroke_slv\n","tia_slv\n","diabetes_slv\n","gerd_slv\n","stomachulcers_slv\n","compressfracback_slv\n","hipfracture_slv\n","osteoarth_slv\n","osteoporosis_slv\n","rheumarth_slv\n","skincancer_slv\n","melanoma_slv\n","cancerkidney_slv\n","canceruterine_slv\n","cancerthroatmouth_slv\n","cancerovarian_slv\n","cancerleukemia_slv\n","cancerpancreatic_slv\n","cancerlymphoma_slv\n","cancerother_slv\n","otherca_specify_slv\n","afib_slv\n","anemia_slv\n","kidneydisease_slv\n","liverdisease_slv\n","cognitivedisorder_slv\n","connectivetissuedz_slv\n","gout_slv\n","depression\n","anxiety_disorder\n","periodontal\n","kidney_dialysis\n","lowerbackpain_3_months\n","lowerbackpain_better_when_move\n","lowerbackpain_stiff_in_morning\n","alcohol_how_often\n","cage_cutdown\n","cage_annoyed\n","cage_guilty\n","cage_eyeopener\n","exh_fatigue_effort\n","exh_fatigue_get_going\n","CigsPerDay_Fagerstrom\n","HowSoonSmoke\n","SmokeMore2hrs\n","CigHateGiveUp\n","FindHardNotSmoke\n","SmokeSickBed\n","Fagerstrom_Index\n","SmokeMenthol\n","CurrentMedUse\n","bagonist\n","bagonistlongact\n","CombcCSBagon\n","CombLABA_LAMA\n","combivent\n","Cortsterinhal\n","CortsterOral\n","ipratrop\n","nebulizer\n","theoph\n","tiotrop\n","CombiventPuffs\n","MacAntibiotic\n","PhosphoInhibitor\n","OsteoporosisMed\n","RA_med\n","currmedhighbp\n","currmedhighcholesterol\n","FluYear\n","PneumoniaYear\n","OsteoMedType_BoneMedication\n","OsteoMedType_Calcitonin\n","OsteoMedType_Calcium\n","OsteoMedType_VitaminD\n","OsteoMedType_Estrogen\n","OsteoMedType_Parathyroid\n","OsteoMedType_EstrogenModulat\n","OsteoMedType_Testosterone\n","OsteoMedType_RANK\n","OsteoMedType_Other\n","RAMedType_BioAgent\n","RAMedType_DiseaseModDrug\n","RAMedType_AntiInflamDrug\n","RAMedType_Steroid\n","HaveCough\n","Cough4Plus\n","CoughAM_yn\n","CoughRestDay\n","Cough3Mo\n","CoughNumYr\n","HavePhlegm\n","PhlegmOften\n","PhlegmAM\n","PhlegmRestDay\n","Phlegm3Mo\n","PhlegmNumYr\n","EpisodeCghPhlm\n","NumEpisodeLastYr\n","YrsEpisodeLast\n","ChstWheezyWhist\n","ShrtBrthAttk\n","ChestWheez12mo\n","WithCold\n","ApartFromCold\n","MoreOnceAWeek\n","MostDaysNights\n","AwakeByCough\n","AwakeByShrtBrth\n","LtdUphill\n","LtdLevelSlow\n","LtdLevelStop\n","LtdLvlStop100\n","LtdNotLeaveHm\n","ERLungProb\n","ERLungProbtimes\n","TreatChestIll\n","TreatChestTimes\n","TreatSteroids\n","TreatSteroiTimes\n","FlareupChestTrb\n","NumberFlareups\n","HadLungSurgery\n","LungProc_BroncDiagMedProb\n","LungProc_BronchTreatCOPD\n","LungProc_LungSurgery\n","LungProc_Biopsy_Lobes\n","LungProc_LungTransplant\n","LungProc_LungVolReductSurg\n","LungProc_Other\n","OtherLungProcedure\n","Chest_Tube\n","Chest_Tube_Age\n","MD_CPAP\n","UseCPAP\n","Last5y_SmokedCig\n","SmokCigNow\n","CigPerDaySmokNow\n","CigSmok24hrs\n","CigSmok2hrs\n","CigSmokHalfHr\n","YearsSmokedLast5Years\n","CigPerDaySmokLast5Years\n","SmokStopAge\n","SmokPipeReg\n","SmokCigarReg\n","ExposureChildren\n","MMRCDyspneaScor\n","COPDExac_NoTrt\n","COPDExac_UsualMed\n","COPDExac_Antib_Ster_Home\n","COPDExac_NewRx_Antib_Ster\n","COPDExac_Hospital\n","COPDExac_ICU\n","COPDExac_BreathingTube\n","AgeWheezWhist\n","AgeWheezWhistDK\n","AgeFirstAttack\n","AgeFirstAttackDK\n","ShrtBrth2Plus\n","MedorTreatAttack\n","SneezRunnyNose\n","ItchyBurningEye\n","UnablWalkCondOth\n","Asthma\n","AsthmaAge\n","AsthmaAgeDK\n","AsthmaDxByDr\n","AsthmaStillHave\n","AsthmaAgeStop\n","AsthmaStopChild\n","AsthmaTreat\n","HayFev\n","HayFevAge\n","HayFevAgeDK\n","HayFevDxByDr\n","HayFevStillHave\n","HayFevAgeStop\n","HayFevStill\n","HayFevTreat\n","BronchAttack\n","BronchDxByDr\n","BronchAge\n","BronchAgeDK\n","BronchTimes\n","Pneumonia\n","PneuDxByDr\n","PneuAge\n","PneuAgeDK\n","PneuTimes\n","ChronBronch\n","ChronBroncDxByDr\n","ChronBroncAge\n","ChronBrncStillHv\n","ChronBroncTreat\n","Emphysema\n","EmphDxByDr\n","EmphAge\n","EmphStillHave\n","EmphTreat\n","COPD\n","CopdDxByDr\n","CopdAge\n","CopdStillHave\n","CopdTreat\n","SleepApnea\n","SleepApDxByDr\n","SleepApAge\n","SleepApStillHav\n","SleepApTreat\n","ChestIllOther\n","ChestOper\n","ChestInj\n","SmokStartAge\n","CigPerDaySmokAvg\n","CigSmok24hrs_NA\n","AgeStartSmokPipe\n","SmokPipeNow\n","QtySmokPipeTob\n","AgeStopSmokPipe\n","SmokTobPerWeek\n","AgeStartSmkCigar\n","SmokCigarNow\n","CigarPerDayNow\n","AgeStopSmokCigar\n","SmokCigarPerWeek\n","MothSmokPreg\n","OthSmokChildYrs\n","OthSmokYrs\n","ExpSmokAtWorkYr\n","SchoolCompleted\n","DustyJobEver\n","DustyJob_slv\n","FumesJobEver\n","FumesJob_slv\n","Worked_slv\n","WorkNow\n","full_part_time_work\n","WorkDustyJobNow\n","ExpFumesNow\n","StopWorkReason\n","retired\n","medically_disabled\n","occupation\n","occupation_change\n","FathChronBronch\n","MothChronBronch\n","FathEmphysema\n","MothEmphysema\n","FathCOPD\n","MothCOPD\n","FathAsthma\n","MothAsthma\n","FathLungCancer\n","MothLungCancer\n","FathCigSmok\n","MothCigSmok\n","Asthma_last5y\n","ChronBronch_last5y\n","COPD_last5y\n","Emphysema_last5y\n","HayFev_last5y\n","Pneumonia_last5y\n","SleepApnea_last5y\n","SmokStopReason_Dx_COPD\n","SmokStopReason_Dx_Heart\n","SmokStopReason_Dx_Cancer\n","SmokStopReason_Dx_OtherMed\n","SmokStopReason_Bad_For_Health\n","SmokStopReason_Cough_phlegm\n","SmokStopReason_haveCOPD\n","SmokStopReason_Other_reason\n","SmokStopReason_Family\n","SmokStopReason_Social\n","SmokStopReason_Less_able_walk\n","SmokStopReason_Too_expensive\n","SmokStopReason_Did_not_like\n","SmokStopReason_No_reason\n","SGRQ_scoreSymptom\n","SGRQ_scoreActive\n","SGRQ_scoreImpact\n","SGRQ_scoreTotal\n","SF36_PF_score\n","SF36_RP_score\n","SF36_RE_score\n","SF36_SF_score\n","SF36_BP_score\n","SF36_VT_score\n","SF36_MH_score\n","SF36_GH_score\n","SF36_PF_t_score\n","SF36_RP_t_score\n","SF36_RE_t_score\n","SF36_SF_t_score\n","SF36_BP_t_score\n","SF36_VT_t_score\n","SF36_MH_t_score\n","SF36_GH_t_score\n","SF36_PCS_score\n","SF36_MCS_score\n","CAT1_cough\n","CAT2_phlegm\n","CAT3_tight\n","CAT4_breathless\n","CAT5_limited\n","CAT6_confident\n","CAT7_sleep\n","CAT8_energy\n","CAT_score\n","HADS_ScorAnx\n","HADS_ScorDepr\n","Income\n","Insurance\n","insurancetype_Medicare\n","insurancetype_Medicare_Private\n","insurancetype_Private\n","insurancetype_Medicaid\n","insurancetype_Military\n","insurancetype_Dont_know\n","PrimaryPhysician\n","DrugCostCovered\n","InternetAccess\n","LungDiseaseInformed\n","PreventativeCare\n","NoPrimaryPhys_DontWantOne\n","NoPrimaryPhys_Dissatisfied\n","NoPrimaryPhys_NoNewPatients\n","NoPrimaryPhys_NotMyIns\n","NoPrimaryPhys_NoHealthIns\n","LackCoverageTx_DontGoDr\n","LackCoverageTx_NotFillRx\n","LackCoverageTx_TookLessRx\n","LackCoverageTx_DontGoHospital\n","LackCoverageTx_GoToER\n","LackCoverageTx_UseFriendsRx\n","LackCoverageTx_NoneOfThese\n","LungDxInfoSrc_Doctors\n","LungDxInfoSrc_Nurses\n","LungDxInfoSrc_RespTher\n","LungDxInfoSrc_PatientOrg\n","LungDxInfoSrc_OtherPts\n","LungDxInfoSrc_Books_Mags\n","LungDxInfoSrc_TV\n","LungDxInfoSrc_Internet\n","LungDxInfoSrc_NoneOfThese\n","LivingSituation_OwnHome\n","LivingSituation_Rent\n","LivingSituation_WithFamily\n","LivingSituation_AssistedLiv\n","LivingSituation_NursingRes\n","LivingSituation_NoPermPlace\n","LivingSituation_WithCaregiver\n","AgeMenstrualStart\n","Pregnant_6moPlus\n","AgePregnant_6mo\n","TimesPregnant_6mo\n","UseBirthControl\n","BirthCntrlUseLstMnth\n","YrsUseBirthControl\n","Postmenopausal\n","PostmenoAge\n","PostmenoTherapy\n","PostmenoTherapyLstMnth\n","PostmenoTherapyYrs\n","postmenopausal_slv\n","postmenotherapy_slv\n","postmenotherapyyrs_slv\n","eCigaretteEver\n","eCigarettesFlavored\n","eCigarettesFlavor\n","eCigaretteStill\n","CigarettesStill\n","RegCigPerDay\n","DecreasedRegCig\n","FewerCigs\n","eCigaretteFreq\n","eCigaretteLast\n","eCigaretteNumLast24Hrs\n","CartridgeSize\n","OtherCartridgeSize\n","Cartridges_1_Week\n","eCig_start_cut_down_tobacco\n","eCigs_Improve_Health\n","smoked_eCig_Days\n","smoked_eCig_Months\n","smoked_eCig_Years\n","TimeSinceStop_eCig_Days\n","TimeSinceStop_eCig_Months\n","TimeSinceStop_eCig_Years\n","past_eCigaretteFreq\n","past_CartridgeSize\n","past_OtherCartridgeSize\n","past_Cartridges_1_Week\n","eCig_start_year\n","eCig_start_month\n","eCigBrand_blu\n","eCigBrand_Henley\n","eCigBrand_Joye\n","eCigBrand_NJOY\n","eCigBrand_V2\n","eCigBrand_Other\n","eCigOtherBrand\n","past_eCigBrand_blu\n","past_eCigBrand_Henley\n","past_eCigBrand_Joye\n","past_eCigBrand_NJOY\n","past_eCigBrand_V2\n","past_eCigBrand_Other\n","past_eCigOtherBrand\n","ecigarette_contains_nicotine\n","ecigarette_contains_cannabis\n","ecigarette_contains_dont_know\n","ecigarette_contains_none\n","ecigarette_contains_other\n","ecigarette_contains_other_a92\n","ecigs_use_since_last_visit\n","vape_bottle_size\n","vape_bottle_last\n","ecigs_con_nicotine\n","ecigs_con_nicotine_cur\n","ecig_product_first_gen_disp\n","ecig_product_first_gen_recharge\n","ecig_product_first_gen_alike\n","ecig_product_first_gen_mini\n","ecig_product_sec_gen_vap\n","ecig_product_third_gen_mods\n","ecig_product_third_gen_vap_mods\n","ecig_product_third_gen_elec\n","ecig_product_dont_know\n","ecig_voltage_a92\n","ecig_voltagechange_a92\n","ecig_temperature_a92\n","ecig_temp_change_a92\n","ecig_cartdgsizeother_a92\n","ecig_bottlelastother_a92\n","wbc\n","neutrophl\n","neutrophl_pct\n","lymphcyt\n","lymphcyt_pct\n","monocyt\n","monocyt_pct\n","eosinphl\n","eosinphl_pct\n","basophl\n","basophl_pct\n","RBC\n","hemoglobin\n","hematocrit\n","MCV\n","MCH\n","MCHC\n","Platelets\n","CBC_QC_problem\n","CBC_problem_category\n","DLco_raw\n","VA\n","VI\n","BHT\n","DLcoPassFail\n","altitude_site\n","DLCO_PB_Correction_Factor\n","DLco_GLI_tr_pb_adjusted\n","Pred_DLco_GLI_tr\n","Pred_DLCO_GLI_Hb\n","DLco_GLI_pp_PbHb_adj\n","DLco_GLI_tr_pp\n","DLco_GLI_tr_z\n","Kco_tr\n","Pred_Kco_tr\n","Kco_tr_pp\n","Kco_tr_z\n","Pred_VA\n","VA_pp\n","VA_z\n","Pred_DLco_Miller\n","DLCOpp_Miller\n","Pred_FEV1\n","Pred_FEV1_LLN\n","Pred_FVC\n","Pred_FVC_LLN\n","Pred_FEV1_FVC\n","Pred_FEV1_FVC_LLN\n","Pred_FEF2575\n","pftused\n","FEV1_post\n","FEV6_post\n","FVC_post\n","FEV1pp_post\n","FVCpp_post\n","FEV1_FVC_post\n","PEF_post\n","FEF2575_post\n","FEV1_pre\n","FEV6_pre\n","FVC_pre\n","FEV1_FVC_pre\n","PEF_pre\n","FEF2575_pre\n","FEV1_utah_y\n","FVC_utah_y\n","FEV1_FVC_utah\n","FEV1pp_utah_y\n","deltaFEV1\n","deltaFVC\n","BDR_pct_FEV1\n","BDR_pct_FVC\n","BDR\n","BODE\n","ATS_PackYears\n","YearsSinceQuit\n","Duration_Smoking\n","Severe_Exacerbations\n","Exacerbation_Frequency\n","Chronic_Bronchitis\n","Chronic_Bronchitis_baseline\n","New_Chronic_Bronchitis_slv\n","ATS_ERS\n","finalgold_visit\n","finalGold\n","NewGOLD_SGRQ\n","ConfirmedNoCT\n","QA_CalciumCalPad\n","FinalApproval\n","CTMissing_Reason\n","CT_scan_year\n","scannerId\n","scanner_make\n","scanner_model_clean\n","sameScannerId\n","sameScannerModel\n","B35f_flag\n","detectors\n","Voxel_axial_insp\n","Voxel_height_insp\n","kernel\n","TLC_Vida\n","pctEmph_Vida\n","Insp_Below950_Vida\n","Perc15_Insp_Vida\n","AttenMean_Insp_Vida\n","AttenStdDev_Insp_Vida\n","FRC_Vida\n","pctGasTrap_Vida\n","Exp_Below856_Vida\n","Perc15_Exp_Vida\n","AttenMean_Exp_Vida\n","AttenStdDev_Exp_Vida\n","pctEmph_UpperLobes\n","pctEmph_LowerLobes\n","pctEmph_UL_LL_ratio\n","UL_pctTotalAirVol\n","ExpInspMeanAtten_ratio_Vida\n","Pi10_SRWA_Vida\n","Pi15_SRWA_Vida\n","WallAreaPct_seg_Vida\n","WallAreaPct_subseg_Vida\n","CT_Visual_Emph_Severity\n","CT_Visual_Emph_Paraseptal\n","CT_Visual_Wall_Thickening\n","CT_Visual_Adjudicated\n","CT_Subtype\n","PFT_CT_numdays\n","TLC_pred_plethy\n","FRC_pred_plethy\n","TLV_pred_MESA\n","TLV_pred_MESA_LLN\n","sit_stand_not_done\n","mask_worn_sit_stand\n","sit_stand_reps\n","grip_strength_performed\n","grip_strength_no_reason\n","grip_strength_dominant_hand\n","grip_strength_hand_tested\n","grip_strength_avg\n","cog_confusion_memory_loss_12m\n","cog_everyday_activities_7d\n","cog_other_activities_7d\n","cog_word_recall\n","cog_clock_draw_adjud\n","clock_adjud_insufficient\n","cog_total_score_adjud\n","capture_pollutedair\n","capture_breathing_chg_seasons\n","capture_activitiesdifficult\n","capture_tireeasily\n","capture_numtimesworkmissed\n","CAPTURE_score\n","capture_rec_action\n","proactive_walking\n","proactive_chores\n","proactive_diff_dress\n","proactive_get_out\n","proactive_avoid_activities\n","proactive_breathless\n","proactive_lack_strength\n","proactive_how_tired\n","proactive_breaks\n","proactive_breathless_level\n","proactive_recover_time\n","proactive_consider_prob\n","dasi_take_care_of_self\n","dasi_walk_indoors\n","dasi_walk_a_block\n","dasi_climb_stairs_or_hill\n","dasi_run_short_distance\n","dasi_light_work\n","dasi_moderate_work\n","dasi_heavy_work\n","dasi_yard_work\n","dasi_sexual_relations\n","dasi_mod_rec_activities\n","dasi_strenuous_sports\n","dasi_score\n","opt_expect_best\n","opt_can_go_wrong\n","opt_my_future\n","opt_go_my_way\n","opt_good_things\n","opt_more_good_things\n","optimism_score\n","smoking_status_change\n","signif_lungchange_suppress\n","ReasonForExclusion\n","flag_LungVol_change_20pct\n","flag_TLV_pp_below70\n","longitudinal_Insp_QCT_ok\n","longitudinal_Exp_QCT_ok\n","Visit_CT_date_diff\n","PFT_CT_date_diff\n","RD_CDR_transform\n","TLC_Thirona\n","FRC_Thirona\n","FRC_TLC_ratio_Thirona\n","pctEmph_Thirona\n","pctEmph_UpperLobes_Thirona\n","pctEmph_LowerLobes_Thirona\n","pctEmph_UL_LL_ratio_Thirona\n","pctGasTrap_Thirona\n","TLC_pp_plethy\n","TLV_pp_mesa\n","perc15_density\n","adj_density_plethy\n","adj_density_mesa\n","log_insp_percentbelow950_total\n","log_exp_percentbelow856_total\n","Insp_LAA950_total_Thirona\n","Insp_LAA950_LUL_Thirona\n","Insp_LAA950_LLL_Thirona\n","Insp_LAA950_RUL_Thirona\n","Insp_LAA950_RML_Thirona\n","Insp_LAA950_RLL_Thirona\n","Exp_LAA856_total_Thirona\n","Exp_LAA856_LUL_Thirona\n","Exp_LAA856_LLL_Thirona\n","Exp_LAA856_RUL_Thirona\n","Exp_LAA856_RML_Thirona\n","Exp_LAA856_RLL_Thirona\n","Perc15_Insp_total_Thirona\n","Perc15_Insp_LUL_Thirona\n","Perc15_Insp_LLL_Thirona\n","Perc15_Insp_RUL_Thirona\n","Perc15_Insp_RML_Thirona\n","Perc15_Insp_RLL_Thirona\n","Perc15_Exp_total_Thirona\n","Perc15_Exp_LUL_Thirona\n","Perc15_Exp_LLL_Thirona\n","Perc15_Exp_RUL_Thirona\n","Perc15_Exp_RML_Thirona\n","Perc15_Exp_RLL_Thirona\n","MeanAtten_Insp_total_Thirona\n","MeanAtten_Insp_LUL_Thirona\n","MeanAtten_Insp_LLL_Thirona\n","MeanAtten_Insp_RUL_Thirona\n","MeanAtten_Insp_RML_Thirona\n","MeanAtten_Insp_RLL_Thirona\n","MeanAtten_Exp_total_Thirona\n","MeanAtten_Exp_LUL_Thirona\n","MeanAtten_Exp_LLL_Thirona\n","MeanAtten_Exp_RUL_Thirona\n","MeanAtten_Exp_RML_Thirona\n","MeanAtten_Exp_RLL_Thirona\n","Insp_totalvolume_total_Thirona\n","Insp_totalvolume_LUL_Thirona\n","Insp_totalvolume_LLL_Thirona\n","Insp_totalvolume_RUL_Thirona\n","Insp_totalvolume_RML_Thirona\n","Insp_totalvolume_RLL_Thirona\n","Exp_totalvolume_total_Thirona\n","Exp_totalvolume_LUL_Thirona\n","Exp_totalvolume_LLL_Thirona\n","Exp_totalvolume_RUL_Thirona\n","Exp_totalvolume_RML_Thirona\n","Exp_totalvolume_RLL_Thirona\n","FRC_TLC_total_Thirona\n","FRC_TLC_LUL_Thirona\n","FRC_TLC_LLL_Thirona\n","FRC_TLC_RUL_Thirona\n","FRC_TLC_RML_Thirona\n","FRC_TLC_RLL_Thirona\n","PRM_pct_emphysema_Thirona\n","PRM_pct_airtrapping_Thirona\n","PRM_pct_normal_Thirona\n","PRM_pct_other_Thirona\n","Pi10_Thirona\n","AWT_seg_Thirona\n","WallAreaPct_seg_Thirona\n","TLC_Slicer\n","pctEmph_Slicer\n","Insp_Below950_Slicer\n","Perc15_Insp_Slicer\n","Slicer_IntensityMean_In\n","Slicer_IntensityStdDev_In\n","Slicer_Insp_Lung_Mass\n","Slicer_Insp_Kurtosis\n","Slicer_Insp_Skewness\n","Slicer_Insp_Histo_Mode\n","HAA700_Insp_Slicer\n","HAA600_Insp_Slicer\n","HAA500_Insp_Slicer\n","HAA250_Insp_Slicer\n","FRC_Slicer\n","pctGasTrap_Slicer\n","Exp_Below856_Slicer\n","Perc15_Exp_Slicer\n","Slicer_IntensityMean_Ex\n","Slicer_IntensityStdDev_Ex\n","Slicer_Exp_Lung_Mass\n","Slicer_Exp_Kurtosis\n","Slicer_Exp_Skewness\n","Slicer_Exp_Histo_Mode\n","pctEmph_UpperLobes_Slicer\n","pctEmph_LowerLobes_Slicer\n","pctEmph_UL_LL_ratio_Slicer\n","pctEmph_UpperThird_Slicer\n","pctEmph_LowerThird_Slicer\n","Slicer_ExpInspMeanAtten_ratio\n","UpperThird_LowerThird_Slicer\n","TLC_CT\n","FRC_CT\n","pctEmph\n","pctGasTrap\n","FRC_TLC_ratio\n","perc15_insp_thirona\n","perc15_exp_thirona\n","meanatten_insp_thirona\n","meanatten_exp_thirona\n","Days_Phase1_Phase2\n","Years_Phase1_Phase2\n","Change_P1_P2_Smoking_Status\n","Change_P1_P2_Gold_class\n","Change_P1_P2_FEV1_ml\n","Change_P1_P2_FEV1pp\n","Change_P1_P2_FEV1_ml_yr\n","Change_P1_P2_MMRC\n","Change_P1_P2_SGRQ_total\n","Change_P1_P2_distwalked\n","Change_P1_P2_O2\n","longitudinal_QCT_Histo_ok\n","longitudinal_QCT_PRM_ok\n","smoking_pattern\n","visit_pattern\n"]}],"source":["for col in insp_df.columns:\n","  print(col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_xuWlb1ioaH"},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1652926631942,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"f9Xe6XABYzSl","outputId":"a52aa575-038f-4eea-978e-0f875339466e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      alcohol_how_often\n","0                   NaN\n","1                   NaN\n","2                   NaN\n","3                   NaN\n","4                   NaN\n","...                 ...\n","8990                NaN\n","8991                NaN\n","8992                NaN\n","8993                NaN\n","8994                NaN\n","\n","[8995 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-4663c85b-29f9-49ea-af31-9bdd9c572fde\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alcohol_how_often</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8990</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8991</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8992</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8993</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8994</th>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8995 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4663c85b-29f9-49ea-af31-9bdd9c572fde')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4663c85b-29f9-49ea-af31-9bdd9c572fde button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4663c85b-29f9-49ea-af31-9bdd9c572fde');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}],"source":["insp_df.iloc[:, 2196:2197]\n","#insp_df.iloc[:, 2024:2025] == 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u6qp3xs5iX24"},"outputs":[],"source":["demo_gender = insp_df.iloc[:,2020:2021]\n","#one hot encoding in gender\n","demo_eth= insp_df.iloc[:,2021:2022]\n","demo_height = insp_df.iloc[:,2041:2042]\n","demo_weight = insp_df.iloc[:,2042:2043]\n","demo_age = insp_df.iloc[:,2027:2028]\n","demo_smoker_status = insp_df.iloc[:, 2025:2026] \n","\n","\n","\n","#include age to the model\n","#age_enroll[:,2029:2030]\n","#age_baseline[:,2027:2028]\n","#age_visit[:,2028:2029]\n","#smokecignow\n","#smokementhol\n","#smoking_status\n","#SmokPipeReg\n","#eCigaretteStill\n","#SmokCigarReg"]},{"cell_type":"code","source":["print(demo_eth)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9dE03a51WfUp","executionInfo":{"status":"ok","timestamp":1652926638056,"user_tz":420,"elapsed":123,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"a5047624-d600-4af6-c6e9-387cb9db8fc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      race\n","0        1\n","1        1\n","2        1\n","3        1\n","4        1\n","...    ...\n","8990     2\n","8991     2\n","8992     2\n","8993     2\n","8994     2\n","\n","[8995 rows x 1 columns]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d0g6dVpWCUU2"},"outputs":[],"source":["ohe = OneHotEncoder(sparse=False)\n","demo_eth = ohe.fit_transform(demo_eth)\n","demo_smoker_status = ohe.fit_transform(demo_smoker_status)"]},{"cell_type":"code","source":["print(demo_eth)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HseFRLT-WwH1","executionInfo":{"status":"ok","timestamp":1652926643396,"user_tz":420,"elapsed":125,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"79e3a5ea-1f50-455b-f61a-e242f0b8913f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," ...\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0L7lujYC2Bi","executionInfo":{"status":"ok","timestamp":1652926646168,"user_tz":420,"elapsed":127,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"3eff169c-b283-47aa-c5f5-ceabe8b74613"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2])"]},"metadata":{},"execution_count":15}],"source":["np.unique(insp_df.iloc[:,2021:2022])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sO46V-zmr4bf"},"outputs":[],"source":["demo_gender = demo_gender - 1\n","#demo_eth = demo_eth/np.max(insp_df.iloc[:,2022:2023]) #one hot encoded variable\n","demo_height = demo_height/np.max(insp_df.iloc[:,2041:2042])\n","demo_weight = demo_weight/np.max(insp_df.iloc[:,2042:2043])\n","demo_age = demo_age/np.max(insp_df.iloc[:,2027:2028])"]},{"cell_type":"code","source":["np.sum(demo_smoker_status, axis = 0)\n","#can remove one of the columns in each,, we can leave it in for regularlization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7WwgaeYOUeDR","executionInfo":{"status":"ok","timestamp":1652926649013,"user_tz":420,"elapsed":121,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"4919c5c1-6b83-447f-ddc0-c12632b970da"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 106., 4235., 4654.])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-XyOSH8w8TY","executionInfo":{"status":"ok","timestamp":1652926650384,"user_tz":420,"elapsed":130,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"1090641d-5654-48da-d815-dff505dfa415"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8995, 9)"]},"metadata":{},"execution_count":18}],"source":["demo_all = np.concatenate([demo_gender, demo_height, demo_weight, demo_eth, demo_age, demo_smoker_status], -1) #demo_weight, demo_smoker_ever, removed due to only one value discrepancy\n","demo_all.shape"]},{"cell_type":"markdown","metadata":{"id":"z0goa5jqGB4N"},"source":["##Creating Training, Validation, and Testing set for all data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYJhPvcqGFrL","executionInfo":{"status":"ok","timestamp":1652926652299,"user_tz":420,"elapsed":209,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"0faceda7-3287-47dd-8258-a54a0dd5adc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[   1    0    0 ...    0    0    0]\n"," [   2    0    0 ...    0    0    0]\n"," [   3    0    0 ...    0    0    0]\n"," ...\n"," [9108    0    0 ...    0    0    0]\n"," [9109    0    0 ...    0    0    0]\n"," [9110    0    0 ...    0    0    0]]\n"]}],"source":["#should this be 2003?\n","insp_df_all = np.array(insp_df.iloc[:,2:2002])\n","print(insp_df_all)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"inHAYkmrIFkW"},"outputs":[],"source":["exp_df_all = np.array(exp_df.iloc[:,2:2002])\n","adm_df_all = np.array(adm_df.iloc[:,2:2002])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OLMaWHW9IRMP","executionInfo":{"status":"ok","timestamp":1652926655507,"user_tz":420,"elapsed":8,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"1087124e-88fb-4508-f1d5-06f02afe2155"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[  1.165   3.266  43.3  ]\n"," [  2.921   3.805 112.3  ]\n"," [  1.814   3.202  59.3  ]\n"," ...\n"," [  1.605   2.171  81.5  ]\n"," [  3.138   3.916  94.8  ]\n"," [  2.378   3.418  80.1  ]]\n"]}],"source":["spiro_df_all = np.array(adm_df.iloc[:,2005:2008])\n","print(spiro_df_all)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vpIqfjhgIbl_"},"outputs":[],"source":["x_temp = np.stack([insp_df_all,exp_df_all,adm_df_all], -1)\n","x_temp = x_temp/np.max(x_temp)\n","y_temp = spiro_df_all"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBSXJf63Irng","executionInfo":{"status":"ok","timestamp":1652926658942,"user_tz":420,"elapsed":5,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"d73ba966-45c0-4c3d-82e5-1104d6367389"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  5.502,   7.719, 159.9  ])"]},"metadata":{},"execution_count":23}],"source":["np.max(y_temp, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kR8k5GF3IvEG"},"outputs":[],"source":["#Standardizes? so that all values are between 0 and 1\n","y_max = (np.max(y_temp[:,0]), np.max(y_temp[:,1]), np.max(y_temp[:,2]))\n","y_min = (np.min(y_temp[:,0]), np.min(y_temp[:,1]), np.min(y_temp[:,2]))\n","y_temp[:,0] = (y_temp[:,0] - np.min(y_temp[:,0])) / (np.max(y_temp[:,0]) - np.min(y_temp[:,0]))\n","y_temp[:,1] = (y_temp[:,1] - np.min(y_temp[:,1])) / (np.max(y_temp[:,1]) - np.min(y_temp[:,1]))\n","y_temp[:,2] = (y_temp[:,2] - np.min(y_temp[:,2])) / (np.max(y_temp[:,2]) - np.min(y_temp[:,2]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CmwvCbzxP-F1"},"outputs":[],"source":["num_training_sample = 6900\n","\n","train_index = np.random.choice(range(x_temp.shape[0]),size = 6900)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"giPkj4NbotaK"},"outputs":[],"source":["order_index = np.arange(0, x_temp.shape[0])\n","np.random.shuffle(order_index)\n","train_index = order_index[0:6900]\n","valid_index = order_index[6901:(6901+946)]\n","\n","test_index = order_index[(6900 + 946):]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QYWJXuHq3Uc"},"outputs":[],"source":["x_train = x_temp[train_index]\n","y_train = y_temp[train_index]\n","x_valid = x_temp[valid_index]\n","y_valid = y_temp[valid_index]\n","\n","#need to creat x test and y test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCAemYc3i-le"},"outputs":[],"source":["demo_train = demo_all[train_index]\n","demo_valid = demo_all[valid_index]"]},{"cell_type":"markdown","metadata":{"id":"054Cv0ovGSab"},"source":["##Neural Networks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-IKFZhdDC0R9"},"outputs":[],"source":["from numpy import mean\n","from numpy import std\n","from numpy import dstack\n","from pandas import read_csv\n","from matplotlib import pyplot\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import tf\n","from keras.callbacks import EarlyStopping\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import Concatenate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNCo7rC-QwOI"},"outputs":[],"source":["es = EarlyStopping(\n","    monitor='val_loss',\n","    patience = 2000,\n","    verbose = 2,\n","    mode = 'min',\n","    restore_best_weights = True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0Rzk_a7Xem2"},"outputs":[],"source":["#on epoch end it will print every epoch at the end\n","class CustomCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs=None):\n","    print(logs.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UeVTZ3T7Ha1z"},"outputs":[],"source":["save_callback = tf.keras.callbacks.ModelCheckpoint(\n","    '/content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5', \n","    save_weights_only=True,\n","    monitor='val_loss',\n","    mode='min',\n","    save_best_only=True,\n","    verbose=1\n",")\n","\n","#weights 1 height, weight, gender, ever had a smoke\n","#weights 2 height, weight, gender, ever had a smoke\n","#wegiths 3 height, weight, ethnicity\n","#weights 4 height, weight, ethnicity, gender, smoker type, age"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVK2vMtJCN0r"},"outputs":[],"source":["#Model Architect 1\n","#model.add(Dropout(0.5)) prevents overfitting, regularization \n","n_samp = 6900\n","hist_size = 2000\n","n_channels = 3\n","n_outputs = 3\n","# number of layers, filters, dense layers, number of neurons in dense layer '100', removing dropout or changing .2 to.5 only, learning rate is important to tune. Could takeout dropout\n","model = Sequential()\n","model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(hist_size,n_channels))) #filters og 32\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu')) #filters og 64\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu')) #Should only be double from filters 64\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu')) \n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))  # layer\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(n_outputs, activation='linear'))\n","model.compile(loss='mse', optimizer= Adam(learning_rate=1e-2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H05y-NpBuavz"},"outputs":[],"source":["#Model Architect 2\n","n_outputs = 3\n","inp = Input((2000,3)) #can mess with number of demographics put in.\n","inp2 = Input((9,))#number of demographics\n","\n","x = Conv1D(filters = 32, kernel_size = 3, activation = 'relu')(inp)\n","x = MaxPooling1D(pool_size = 2)(x)\n","x = Conv1D(filters = 32, kernel_size = 3, activation = 'relu')(inp)\n","x = MaxPooling1D(pool_size = 2)(x)\n","x = Conv1D(filters = 32, kernel_size = 3, activation = 'relu')(inp)\n","x = MaxPooling1D(pool_size = 2)(x)\n","x = Conv1D(filters = 32, kernel_size = 3, activation = 'relu')(inp)\n","#x = Dropout(0.5)(x)\n","x = MaxPooling1D(pool_size = 2)(x)\n","#x = Dropout(0.5)(x)\n","x = Conv1D(filters = 64, kernel_size = 3, activation = 'relu')(x)\n","x = MaxPooling1D(pool_size = 2)(x)\n","x = Conv1D(filters = 64, kernel_size = 3, activation = 'relu')(x)\n","x = MaxPooling1D(pool_size = 2)(x)\n","x = Conv1D(filters = 64, kernel_size = 3, activation = 'relu')(x)\n","x = MaxPooling1D(pool_size = 2)(x)\n","x = Conv1D(filters = 64, kernel_size = 3, activation = 'relu')(x)\n","x = MaxPooling1D(pool_size = 2)(x)\n","x = Conv1D(filters = 64, kernel_size = 3, activation = 'relu')(x)\n","x = MaxPooling1D(pool_size = 2)(x)\n","#x = Dropout(0.5)(x)\n","x = Conv1D(filters = 128, kernel_size = 3, activation = 'relu')(x)\n","#x = Dropout(0.5)(x)\n","x = MaxPooling1D(pool_size = 2)(x)\n","x = Conv1D(filters = 128, kernel_size = 3, activation = 'relu')(x)\n","x = MaxPooling1D(pool_size = 2)(x)#put more of these \n","x = Conv1D(filters = 128, kernel_size = 3, activation = 'relu')(x)\n","#x = Dropout(0.5)(x)\n","x = MaxPooling1D(pool_size = 2)(x)#put more of these \n","#x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","#print(inp2)\n","x = Concatenate(axis=-1)([x, inp2])\n","x =Dense(100, activation = 'relu')(x) #same as what's inputted in the first architecture, can change dense number but is memory heavy\n","x = Dense(n_outputs, activation = 'linear')(x) #will take 31,000 features and take inputs from demo variables and concat and then predicting, gonna need more dense layers, and reduce \n","model = Model([inp, inp2], x)\n","model.compile(loss='mse', optimizer= Adam(learning_rate=1e-6))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJhJK3vCyFcC","outputId":"eb96190b-48fb-485a-b04b-73117618d7a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2902/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2902: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0064\n","Epoch 2903/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2903: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2904/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2904: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2905/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2905: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2906/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2906: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2907/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2907: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2908/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2908: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2909/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2909: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2910/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2910: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2911/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2911: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2912/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0066\n","Epoch 2912: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2913/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2913: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2914/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2914: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2915/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2915: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2916/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2916: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0064\n","Epoch 2917/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2917: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2918/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2918: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2919/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2919: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2920/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2920: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2921/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2921: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2922/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2922: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2923/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2923: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2924/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2924: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2925/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2925: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2926/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2926: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2927/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0066\n","Epoch 2927: val_loss improved from 0.00631 to 0.00631, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2928/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2928: val_loss improved from 0.00631 to 0.00631, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2929/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2929: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2930/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2930: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2931/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2931: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2932/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2932: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2933/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2933: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2934/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2934: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2935/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2935: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2936/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2936: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2937/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2937: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2938/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2938: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2939/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2939: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2940/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2940: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2941/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2941: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2942/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2942: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2943/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2943: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2944/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2944: val_loss did not improve from 0.00631\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2945/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2945: val_loss improved from 0.00631 to 0.00630, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 13ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2946/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2946: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0064\n","Epoch 2947/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2947: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2948/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2948: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2949/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2949: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2950/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2950: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2951/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2951: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2952/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0066\n","Epoch 2952: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0066 - val_loss: 0.0063\n","Epoch 2953/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2953: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2954/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2954: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2955/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2955: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2956/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2956: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2957/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2957: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2958/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2958: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2959/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2959: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2960/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2960: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2961/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2961: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2962/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2962: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2963/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2963: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2964/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2964: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0064\n","Epoch 2965/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2965: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2966/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2966: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2967/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2967: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2968/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 2968: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2969/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2969: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2970/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2970: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2971/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2971: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2972/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2972: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2973/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2973: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2974/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2974: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2975/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2975: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2976/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2976: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2977/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2977: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2978/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2978: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2979/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2979: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2980/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2980: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2981/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2981: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2982/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2982: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2983/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2983: val_loss improved from 0.00630 to 0.00630, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2984/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2984: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2985/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2985: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2986/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2986: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2987/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2987: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2988/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2988: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2989/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2989: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2990/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2990: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2991/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2991: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2992/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2992: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2993/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 2993: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2994/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2994: val_loss improved from 0.00630 to 0.00630, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2995/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2995: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2996/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2996: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2997/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2997: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2998/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2998: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 2999/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 2999: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3000/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3000: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3001/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3001: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3002/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3002: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3003/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3003: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3004/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3004: val_loss improved from 0.00630 to 0.00630, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 13ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3005/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3005: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3006/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3006: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3007/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3007: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3008/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3008: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3009/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3009: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0064\n","Epoch 3010/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3010: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3011/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3011: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3012/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3012: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3013/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3013: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3014/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3014: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3015/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3015: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3016/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3016: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3017/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3017: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3018/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3018: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3019/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3019: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3020/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3020: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3021/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3021: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3022/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3022: val_loss did not improve from 0.00630\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3023/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3023: val_loss improved from 0.00630 to 0.00629, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3024/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0066\n","Epoch 3024: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3025/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3025: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3026/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3026: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3027/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3027: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3028/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3028: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3029/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3029: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3030/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3030: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3031/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3031: val_loss improved from 0.00629 to 0.00629, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3032/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3032: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3033/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3033: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3034/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3034: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3035/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3035: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3036/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3036: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3037/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3037: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3038/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3038: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3039/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3039: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3040/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3040: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3041/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3041: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3042/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3042: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3043/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3043: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3044/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3044: val_loss improved from 0.00629 to 0.00629, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3045/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3045: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3046/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3046: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3047/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3047: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3048/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3048: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3049/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3049: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3050/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3050: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3051/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3051: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3052/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3052: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3053/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3053: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3054/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3054: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3055/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3055: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3056/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3056: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3057/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3057: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0064\n","Epoch 3058/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3058: val_loss did not improve from 0.00629\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3059/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3059: val_loss improved from 0.00629 to 0.00628, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3060/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3060: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3061/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3061: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3062/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3062: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3063/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3063: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3064/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3064: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3065/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3065: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3066/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3066: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3067/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3067: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3068/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3068: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3069/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3069: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3070/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3070: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3071/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3071: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3072/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3072: val_loss improved from 0.00628 to 0.00628, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3073/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3073: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3074/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3074: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3075/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3075: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3076/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3076: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3077/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3077: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3078/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3078: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3079/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3079: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3080/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3080: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3081/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3081: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3082/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3082: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3083/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3083: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3084/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3084: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3085/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3085: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3086/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3086: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3087/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3087: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3088/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3088: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3089/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3089: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3090/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3090: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3091/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3091: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3092/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3092: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3093/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3093: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3094/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3094: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3095/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3095: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3096/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3096: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3097/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3097: val_loss improved from 0.00628 to 0.00628, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3098/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3098: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3099/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3099: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3100/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3100: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3101/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3101: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3102/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3102: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3103/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3103: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3104/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3104: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3105/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3105: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3106/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3106: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3107/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3107: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3108/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3108: val_loss improved from 0.00628 to 0.00628, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3109/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3109: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3110/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3110: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3111/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3111: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3112/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3112: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3113/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3113: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3114/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3114: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3115/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3115: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3116/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3116: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3117/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3117: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3118/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3118: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3119/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3119: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3120/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3120: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3121/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3121: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3122/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3122: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3123/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3123: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3124/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3124: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3125/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3125: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3126/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3126: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3127/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3127: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3128/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3128: val_loss improved from 0.00628 to 0.00628, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3129/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3129: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3130/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3130: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3131/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3131: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3132/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3132: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3133/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3133: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3134/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3134: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3135/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3135: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3136/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3136: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3137/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3137: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3138/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3138: val_loss did not improve from 0.00628\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3139/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3139: val_loss improved from 0.00628 to 0.00627, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3140/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3140: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3141/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3141: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3142/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3142: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3143/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3143: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3144/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3144: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3145/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3145: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3146/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3146: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3147/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3147: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3148/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3148: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3149/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3149: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3150/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3150: val_loss improved from 0.00627 to 0.00627, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3151/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3151: val_loss improved from 0.00627 to 0.00627, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3152/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3152: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3153/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3153: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3154/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3154: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3155/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3155: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3156/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3156: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3157/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3157: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3158/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3158: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3159/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3159: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3160/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0065\n","Epoch 3160: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3161/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3161: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3162/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3162: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3163/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3163: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3164/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3164: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3165/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3165: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3166/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3166: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3167/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3167: val_loss did not improve from 0.00627\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3168/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3168: val_loss improved from 0.00627 to 0.00626, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3169/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3169: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3170/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3170: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3171/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3171: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3172/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3172: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3173/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3173: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3174/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3174: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3175/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3175: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3176/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3176: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3177/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3177: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3178/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3178: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3179/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3179: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3180/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3180: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3181/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3181: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0063\n","Epoch 3182/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3182: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3183/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3183: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3184/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3184: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3185/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3185: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3186/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3186: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3187/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3187: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3188/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3188: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3189/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3189: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3190/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3190: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3191/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3191: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3192/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3192: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3193/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3193: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3194/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3194: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3195/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3195: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3196/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3196: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3197/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3197: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0064\n","Epoch 3198/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3198: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3199/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3199: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3200/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3200: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3201/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3201: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3202/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3202: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3203/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3203: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3204/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3204: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3205/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3205: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 12ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3206/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3206: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3207/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3207: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3208/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3208: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3209/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3209: val_loss improved from 0.00626 to 0.00626, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3210/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3210: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3211/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3211: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3212/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3212: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3213/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3213: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3214/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3214: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3215/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3215: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3216/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3216: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3217/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3217: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3218/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3218: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3219/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3219: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3220/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3220: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3221/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3221: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3222/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3222: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3223/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3223: val_loss improved from 0.00626 to 0.00626, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3224/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3224: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3225/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3225: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3226/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3226: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3227/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3227: val_loss did not improve from 0.00626\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3228/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3228: val_loss improved from 0.00626 to 0.00625, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3229/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3229: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3230/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3230: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3231/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3231: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3232/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3232: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3233/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3233: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3234/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3234: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3235/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3235: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3236/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3236: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3237/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3237: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3238/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3238: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3239/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3239: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3240/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3240: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3241/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3241: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3242/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3242: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3243/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3243: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3244/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3244: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3245/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3245: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3246/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3246: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3247/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3247: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3248/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3248: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3249/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3249: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3250/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3250: val_loss improved from 0.00625 to 0.00625, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3251/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3251: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3252/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3252: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3253/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3253: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3254/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3254: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3255/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3255: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3256/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3256: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3257/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3257: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3258/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3258: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3259/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3259: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3260/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3260: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3261/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3261: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3262/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3262: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3263/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3263: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3264/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3264: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3265/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3265: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3266/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3266: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3267/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3267: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3268/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3268: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3269/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3269: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3270/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0065\n","Epoch 3270: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3271/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3271: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3272/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3272: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3273/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3273: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3274/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3274: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3275/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3275: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3276/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3276: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3277/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3277: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3278/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3278: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3279/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3279: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3280/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3280: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3281/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3281: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3282/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3282: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3283/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3283: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3284/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3284: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3285/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3285: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3286/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3286: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3287/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3287: val_loss improved from 0.00625 to 0.00625, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3288/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3288: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3289/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3289: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3290/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3290: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3291/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3291: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3292/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3292: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3293/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3293: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3294/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3294: val_loss improved from 0.00625 to 0.00625, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3295/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3295: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3296/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3296: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3297/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3297: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3298/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3298: val_loss improved from 0.00625 to 0.00625, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3299/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3299: val_loss did not improve from 0.00625\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3300/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3300: val_loss improved from 0.00625 to 0.00624, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3301/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3301: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3302/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3302: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3303/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3303: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3304/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3304: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3305/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3305: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3306/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3306: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3307/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3307: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3308/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3308: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3309/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3309: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3310/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3310: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3311/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3311: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3312/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3312: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3313/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3313: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3314/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3314: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3315/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3315: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3316/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3316: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3317/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3317: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3318/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3318: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3319/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3319: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3320/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3320: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3321/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3321: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3322/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3322: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3323/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3323: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3324/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3324: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3325/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3325: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3326/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3326: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3327/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3327: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3328/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3328: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3329/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3329: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3330/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3330: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3331/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3331: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3332/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3332: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3333/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3333: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3334/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3334: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3335/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3335: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3336/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3336: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3337/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3337: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3338/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3338: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3339/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3339: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3340/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3340: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3341/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3341: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3342/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3342: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3343/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3343: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3344/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3344: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3345/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3345: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3346/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3346: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3347/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3347: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3348/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3348: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3349/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3349: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3350/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3350: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3351/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3351: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3352/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3352: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3353/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3353: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3354/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3354: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3355/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3355: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3356/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3356: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0064\n","Epoch 3357/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3357: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3358/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3358: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3359/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3359: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3360/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3360: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3361/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3361: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3362/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3362: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3363/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3363: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3364/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3364: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3365/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3365: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3366/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3366: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3367/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3367: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3368/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3368: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3369/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3369: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3370/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3370: val_loss improved from 0.00624 to 0.00624, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3371/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3371: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3372/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3372: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3373/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3373: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3374/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3374: val_loss did not improve from 0.00624\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3375/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3375: val_loss improved from 0.00624 to 0.00623, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3376/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3376: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3377/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3377: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3378/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3378: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3379/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3379: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3380/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3380: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3381/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3381: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3382/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3382: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3383/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3383: val_loss improved from 0.00623 to 0.00623, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3384/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3384: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3385/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3385: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3386/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3386: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3387/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3387: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3388/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3388: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3389/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3389: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3390/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3390: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3391/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3391: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3392/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3392: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3393/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3393: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3394/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3394: val_loss improved from 0.00623 to 0.00623, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3395/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3395: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3396/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3396: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3397/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3397: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3398/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3398: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3399/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3399: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3400/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3400: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3401/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3401: val_loss improved from 0.00623 to 0.00623, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3402/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3402: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3403/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3403: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3404/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3404: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3405/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3405: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3406/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3406: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3407/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3407: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3408/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3408: val_loss did not improve from 0.00623\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3409/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3409: val_loss improved from 0.00623 to 0.00622, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3410/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3410: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3411/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3411: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3412/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3412: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3413/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3413: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3414/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3414: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3415/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3415: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3416/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3416: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3417/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3417: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3418/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3418: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3419/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3419: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3420/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3420: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3421/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3421: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3422/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3422: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3423/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3423: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3424/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3424: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3425/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3425: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0063\n","Epoch 3426/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3426: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3427/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3427: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3428/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0064\n","Epoch 3428: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3429/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3429: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3430/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3430: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3431/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3431: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3432/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3432: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3433/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3433: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3434/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3434: val_loss improved from 0.00622 to 0.00622, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3435/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3435: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0064 - val_loss: 0.0062\n","Epoch 3436/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3436: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3437/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3437: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3438/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3438: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3439/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3439: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3440/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3440: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3441/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3441: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3442/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3442: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3443/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3443: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3444/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3444: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3445/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3445: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3446/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3446: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3447/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3447: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3448/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3448: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3449/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3449: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3450/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3450: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3451/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3451: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3452/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3452: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3453/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3453: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3454/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3454: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3455/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3455: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3456/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3456: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3457/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0064\n","Epoch 3457: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3458/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3458: val_loss improved from 0.00622 to 0.00622, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3459/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3459: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3460/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3460: val_loss improved from 0.00622 to 0.00622, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3461/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3461: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3462/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3462: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3463/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3463: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3464/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3464: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3465/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3465: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3466/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3466: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3467/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3467: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3468/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3468: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3469/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3469: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3470/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3470: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3471/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3471: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3472/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3472: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3473/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3473: val_loss did not improve from 0.00622\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3474/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3474: val_loss improved from 0.00622 to 0.00621, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3475/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3475: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3476/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3476: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3477/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3477: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3478/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3478: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3479/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3479: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3480/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3480: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3481/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3481: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3482/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3482: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3483/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3483: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3484/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3484: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3485/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3485: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3486/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3486: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3487/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3487: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3488/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3488: val_loss improved from 0.00621 to 0.00621, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3489/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3489: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3490/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3490: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3491/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3491: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3492/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3492: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3493/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3493: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3494/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3494: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3495/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3495: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3496/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3496: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3497/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3497: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3498/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3498: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3499/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3499: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3500/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3500: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3501/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3501: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3502/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3502: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3503/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3503: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3504/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3504: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3505/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3505: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3506/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3506: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3507/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3507: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3508/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3508: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3509/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3509: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3510/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3510: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3511/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3511: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3512/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3512: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3513/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3513: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3514/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3514: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3515/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3515: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3516/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3516: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3517/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3517: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3518/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3518: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3519/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3519: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3520/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3520: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3521/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3521: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3522/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3522: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3523/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3523: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3524/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3524: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3525/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3525: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3526/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3526: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3527/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3527: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3528/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3528: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3529/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3529: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3530/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3530: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3531/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3531: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3532/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3532: val_loss improved from 0.00621 to 0.00621, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3533/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3533: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3534/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3534: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3535/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3535: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3536/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3536: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3537/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3537: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3538/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3538: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3539/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3539: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3540/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3540: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3541/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3541: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3542/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3542: val_loss did not improve from 0.00621\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3543/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3543: val_loss improved from 0.00621 to 0.00620, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3544/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3544: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3545/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3545: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3546/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3546: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3547/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3547: val_loss improved from 0.00620 to 0.00620, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3548/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3548: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3549/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3549: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3550/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3550: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3551/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3551: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3552/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3552: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3553/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3553: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3554/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3554: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3555/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3555: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3556/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3556: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3557/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3557: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3558/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3558: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3559/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3559: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3560/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3560: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3561/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3561: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3562/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3562: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3563/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3563: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3564/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3564: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3565/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3565: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3566/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3566: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3567/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3567: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3568/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3568: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3569/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3569: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3570/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3570: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3571/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3571: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3572/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3572: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3573/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3573: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3574/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3574: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3575/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3575: val_loss did not improve from 0.00620\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3576/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3576: val_loss improved from 0.00620 to 0.00619, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3577/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3577: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3578/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3578: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3579/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3579: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3580/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3580: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3581/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3581: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3582/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3582: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3583/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3583: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3584/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3584: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3585/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3585: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3586/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3586: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3587/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3587: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3588/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3588: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3589/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3589: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3590/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3590: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3591/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3591: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3592/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3592: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3593/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3593: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3594/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3594: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3595/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3595: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3596/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3596: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3597/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3597: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3598/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3598: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3599/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3599: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3600/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3600: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3601/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3601: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3602/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3602: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3603/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3603: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3604/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3604: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3605/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3605: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3606/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3606: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3607/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3607: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3608/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3608: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3609/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3609: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3610/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3610: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3611/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3611: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3612/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3612: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3613/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3613: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3614/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3614: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3615/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3615: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3616/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3616: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3617/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3617: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3618/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3618: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3619/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3619: val_loss improved from 0.00619 to 0.00619, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3620/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3620: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3621/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3621: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3622/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3622: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3623/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3623: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3624/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3624: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3625/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3625: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3626/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3626: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3627/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3627: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3628/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3628: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3629/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3629: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3630/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3630: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3631/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3631: val_loss improved from 0.00619 to 0.00619, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3632/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3632: val_loss improved from 0.00619 to 0.00619, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3633/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3633: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3634/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3634: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3635/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3635: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3636/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3636: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3637/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3637: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3638/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3638: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3639/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3639: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3640/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3640: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3641/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3641: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3642/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3642: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3643/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3643: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3644/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3644: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3645/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3645: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3646/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3646: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3647/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3647: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3648/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3648: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3649/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3649: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3650/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3650: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3651/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3651: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3652/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3652: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3653/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3653: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3654/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3654: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3655/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3655: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3656/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3656: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0063\n","Epoch 3657/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3657: val_loss did not improve from 0.00619\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3658/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3658: val_loss improved from 0.00619 to 0.00618, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3659/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3659: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3660/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3660: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3661/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3661: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3662/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3662: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3663/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3663: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3664/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3664: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3665/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3665: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3666/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3666: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3667/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3667: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3668/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3668: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3669/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3669: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3670/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3670: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3671/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3671: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3672/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0063\n","Epoch 3672: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3673/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3673: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3674/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3674: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3675/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3675: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3676/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3676: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3677/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3677: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3678/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3678: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3679/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3679: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3680/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3680: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3681/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3681: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3682/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3682: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3683/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3683: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3684/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3684: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3685/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3685: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3686/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3686: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3687/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3687: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3688/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3688: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3689/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3689: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3690/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3690: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3691/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3691: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3692/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3692: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3693/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3693: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3694/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3694: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3695/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3695: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3696/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3696: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3697/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3697: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3698/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3698: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3699/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3699: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3700/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3700: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3701/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3701: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3702/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3702: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n","Epoch 3703/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3703: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3704/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3704: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3705/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3705: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3706/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3706: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3707/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3707: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3708/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3708: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3709/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3709: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3710/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3710: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3711/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3711: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3712/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3712: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3713/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3713: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3714/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3714: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3715/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3715: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0063\n","Epoch 3716/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3716: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3717/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3717: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3718/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3718: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3719/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3719: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3720/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3720: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3721/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3721: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3722/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3722: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3723/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0063\n","Epoch 3723: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3724/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3724: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3725/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3725: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3726/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3726: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3727/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3727: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3728/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3728: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3729/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3729: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3730/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3730: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3731/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3731: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3732/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3732: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3733/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3733: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3734/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3734: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3735/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3735: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3736/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3736: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3737/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3737: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3738/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3738: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3739/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3739: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3740/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3740: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3741/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3741: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3742/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3742: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3743/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3743: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3744/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3744: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3745/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3745: val_loss improved from 0.00618 to 0.00618, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3746/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3746: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3747/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3747: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3748/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3748: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3749/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3749: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3750/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3750: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3751/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3751: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3752/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3752: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3753/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3753: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3754/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3754: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3755/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3755: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3756/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3756: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3757/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3757: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3758/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3758: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3759/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3759: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3760/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3760: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3761/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3761: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3762/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3762: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3763/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3763: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3764/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3764: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3765/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3765: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3766/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3766: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3767/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3767: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3768/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3768: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3769/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3769: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3770/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3770: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0063\n","Epoch 3771/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3771: val_loss improved from 0.00618 to 0.00618, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3772/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3772: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3773/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3773: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3774/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3774: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3775/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3775: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3776/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3776: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0063\n","Epoch 3777/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3777: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3778/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3778: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3779/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3779: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3780/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3780: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3781/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3781: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3782/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3782: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3783/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3783: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3784/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3784: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3785/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3785: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3786/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3786: val_loss improved from 0.00618 to 0.00618, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3787/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3787: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3788/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3788: val_loss did not improve from 0.00618\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3789/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3789: val_loss improved from 0.00618 to 0.00617, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3790/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3790: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3791/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3791: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3792/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3792: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3793/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3793: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3794/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3794: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3795/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3795: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3796/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3796: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3797/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3797: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3798/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3798: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3799/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3799: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3800/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3800: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3801/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3801: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3802/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3802: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3803/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3803: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3804/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3804: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3805/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3805: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3806/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3806: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3807/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3807: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3808/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3808: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3809/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3809: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3810/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3810: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3811/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3811: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3812/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3812: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3813/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3813: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3814/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3814: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3815/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3815: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3816/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3816: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3817/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3817: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3818/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3818: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3819/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3819: val_loss improved from 0.00617 to 0.00617, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3820/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3820: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3821/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3821: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3822/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3822: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3823/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3823: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3824/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3824: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3825/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3825: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3826/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3826: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3827/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3827: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3828/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3828: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3829/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3829: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3830/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3830: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3831/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3831: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3832/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3832: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3833/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3833: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3834/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3834: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3835/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3835: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3836/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3836: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3837/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3837: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3838/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3838: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3839/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3839: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3840/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3840: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3841/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3841: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3842/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3842: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3843/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3843: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3844/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3844: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3845/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3845: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3846/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3846: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3847/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3847: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3848/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3848: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3849/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3849: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3850/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3850: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3851/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3851: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3852/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3852: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3853/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3853: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3854/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3854: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3855/10000\n","211/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3855: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3856/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3856: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3857/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3857: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3858/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3858: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3859/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3859: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3860/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3860: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3861/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3861: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3862/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3862: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3863/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3863: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3864/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3864: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3865/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3865: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3866/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3866: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3867/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3867: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3868/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3868: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3869/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3869: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3870/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3870: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0063\n","Epoch 3871/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3871: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3872/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3872: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3873/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3873: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3874/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3874: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3875/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3875: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3876/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3876: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3877/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3877: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3878/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3878: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3879/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3879: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3880/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3880: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3881/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3881: val_loss did not improve from 0.00617\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3882/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3882: val_loss improved from 0.00617 to 0.00616, saving model to /content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 3s 12ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3883/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3883: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3884/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3884: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3885/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3885: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3886/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3886: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3887/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3887: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3888/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3888: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3889/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3889: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3890/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3890: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3891/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3891: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3892/10000\n","214/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3892: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3893/10000\n","216/216 [==============================] - ETA: 0s - loss: 0.0062\n","Epoch 3893: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3894/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3894: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3895/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3895: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3896/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3896: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3897/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3897: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3898/10000\n","212/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3898: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3899/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3899: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3900/10000\n","215/216 [============================>.] - ETA: 0s - loss: 0.0062\n","Epoch 3900: val_loss did not improve from 0.00616\n","dict_keys(['loss', 'val_loss'])\n","216/216 [==============================] - 2s 11ms/step - loss: 0.0062 - val_loss: 0.0062\n","Epoch 3901/10000\n","213/216 [============================>.] - ETA: 0s - loss: 0.0062"]}],"source":["#model fit Architect 2\n","model.fit([x_train,demo_train], y_train, validation_data = [[x_valid,demo_valid], y_valid], epochs = 10000, callbacks=[save_callback,CustomCallback(),es])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAQTLajgCzq9","executionInfo":{"status":"ok","timestamp":1650550930403,"user_tz":420,"elapsed":52,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"15b524c8-ca4e-43c3-95b7-91f911cf63cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 2000, 3)]    0           []                               \n","                                                                                                  \n"," conv1d_3 (Conv1D)              (None, 1998, 32)     320         ['input_1[0][0]']                \n","                                                                                                  \n"," max_pooling1d_3 (MaxPooling1D)  (None, 999, 32)     0           ['conv1d_3[0][0]']               \n","                                                                                                  \n"," conv1d_4 (Conv1D)              (None, 997, 64)      6208        ['max_pooling1d_3[0][0]']        \n","                                                                                                  \n"," max_pooling1d_4 (MaxPooling1D)  (None, 498, 64)     0           ['conv1d_4[0][0]']               \n","                                                                                                  \n"," conv1d_5 (Conv1D)              (None, 496, 64)      12352       ['max_pooling1d_4[0][0]']        \n","                                                                                                  \n"," max_pooling1d_5 (MaxPooling1D)  (None, 248, 64)     0           ['conv1d_5[0][0]']               \n","                                                                                                  \n"," conv1d_6 (Conv1D)              (None, 246, 64)      12352       ['max_pooling1d_5[0][0]']        \n","                                                                                                  \n"," max_pooling1d_6 (MaxPooling1D)  (None, 123, 64)     0           ['conv1d_6[0][0]']               \n","                                                                                                  \n"," conv1d_7 (Conv1D)              (None, 121, 64)      12352       ['max_pooling1d_6[0][0]']        \n","                                                                                                  \n"," max_pooling1d_7 (MaxPooling1D)  (None, 60, 64)      0           ['conv1d_7[0][0]']               \n","                                                                                                  \n"," conv1d_8 (Conv1D)              (None, 58, 64)       12352       ['max_pooling1d_7[0][0]']        \n","                                                                                                  \n"," max_pooling1d_8 (MaxPooling1D)  (None, 29, 64)      0           ['conv1d_8[0][0]']               \n","                                                                                                  \n"," conv1d_9 (Conv1D)              (None, 27, 128)      24704       ['max_pooling1d_8[0][0]']        \n","                                                                                                  \n"," max_pooling1d_9 (MaxPooling1D)  (None, 13, 128)     0           ['conv1d_9[0][0]']               \n","                                                                                                  \n"," conv1d_10 (Conv1D)             (None, 11, 128)      49280       ['max_pooling1d_9[0][0]']        \n","                                                                                                  \n"," max_pooling1d_10 (MaxPooling1D  (None, 5, 128)      0           ['conv1d_10[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv1d_11 (Conv1D)             (None, 3, 128)       49280       ['max_pooling1d_10[0][0]']       \n","                                                                                                  \n"," max_pooling1d_11 (MaxPooling1D  (None, 1, 128)      0           ['conv1d_11[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," flatten (Flatten)              (None, 128)          0           ['max_pooling1d_11[0][0]']       \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 9)]          0           []                               \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 137)          0           ['flatten[0][0]',                \n","                                                                  'input_2[0][0]']                \n","                                                                                                  \n"," dense (Dense)                  (None, 100)          13800       ['concatenate[0][0]']            \n","                                                                                                  \n"," dense_1 (Dense)                (None, 3)            303         ['dense[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 193,303\n","Trainable params: 193,303\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":624},"executionInfo":{"elapsed":576,"status":"error","timestamp":1649362516583,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"MOvk1VBPIqXu","outputId":"7283fde2-d9d2-45d8-95a3-9b9dcc795ad7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5000\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-841bfd698e85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Model Fit Architect 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCustomCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 2000, 3) dtype=float32>]\n"]}],"source":["#Model Fit Architect 1\n","model.fit(x_train, y_train, validation_data = [x_valid, y_valid], epochs = 5000, callbacks=[save_callback,CustomCallback(),es])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USjgYSd86FRo"},"outputs":[],"source":["model.load_weights('/content/drive/Shareddrives/Hasenstab Lab/Data/COPDGene/univariate_histograms/CNN_Callback/weights4.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9lk0Tipo0se","executionInfo":{"status":"ok","timestamp":1650550941354,"user_tz":420,"elapsed":2396,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"209ea69c-588d-47e9-9529-e75463d4fe1e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(946, 3)"]},"metadata":{},"execution_count":34}],"source":["pred_valid = model.predict([x_valid, demo_valid])\n","pred_valid.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yeITQAC8BFx0"},"outputs":[],"source":["#creating new variable to represent y_valid\n","y_valid_native = y_valid + 0."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vlv2v4_lA98C"},"outputs":[],"source":["y_valid_native[:,0] = (y_valid[:,0] * (y_max[0] - y_min[0])) + y_min[0]\n","y_valid_native[:,1] = (y_valid[:,1] * (y_max[1] - y_min[1])) + y_min[1]\n","y_valid_native[:,2] = (y_valid[:,2] * (y_max[2] - y_min[2])) + y_min[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J1mcoIpBBdVF"},"outputs":[],"source":["pred_valid_native = pred_valid + 0."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWlC2P7wBcdJ"},"outputs":[],"source":["pred_valid_native[:,0] = (pred_valid[:,0] * (y_max[0] - y_min[0])) + y_min[0]\n","pred_valid_native[:,1] = (pred_valid[:,1] * (y_max[1] - y_min[1])) + y_min[1]\n","pred_valid_native[:,2] = (pred_valid[:,2] * (y_max[2] - y_min[2])) + y_min[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oc3rP4-cBv4y"},"outputs":[],"source":["pred_ratio = pred_valid_native[:,0] / pred_valid_native[:,1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p36x3Vi3B6Rl"},"outputs":[],"source":["y_ratio = y_valid_native[:,0] / y_valid_native[:,1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"Crz1UboaB8rI","executionInfo":{"status":"ok","timestamp":1650550953139,"user_tz":420,"elapsed":678,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"23685fe3-cb1d-4e43-c44e-ffd00b8781fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7f0354282c90>"]},"metadata":{},"execution_count":41},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.scatter(pred_ratio,y_ratio)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugx-9ysUCGcc","executionInfo":{"status":"ok","timestamp":1650550956489,"user_tz":420,"elapsed":314,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"42ac53de-e169-4783-9e8d-ad1095a3bec9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8403805496828752"]},"metadata":{},"execution_count":42}],"source":["#preliminary predictive accuracy\n","(np.sum((pred_ratio > 0.7) & (y_ratio > 0.7)) + np.sum((pred_ratio < 0.7) & (y_ratio < 0.7))) / pred_ratio.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"f4_f3b1UpyuB","executionInfo":{"status":"ok","timestamp":1650550958618,"user_tz":420,"elapsed":678,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"1d874ea9-9bd5-4c45-8194-ee12afb2488c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7f0355a798d0>"]},"metadata":{},"execution_count":43},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.scatter(y_valid[:,2], y_valid[:,0]/y_valid[:,1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"fNZ-WmDZ39nc","executionInfo":{"status":"ok","timestamp":1650550961067,"user_tz":420,"elapsed":577,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"d50bdc75-fefc-4604-8aea-3cc0f3368ee0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7f0355575f50>"]},"metadata":{},"execution_count":44},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.scatter(pred_valid[:,2], pred_valid[:,0]/pred_valid[:,1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"aH4g8L1XOkmZ","executionInfo":{"status":"ok","timestamp":1650550964601,"user_tz":420,"elapsed":33,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"ebdb6fb1-3ebe-42e7-8758-b6ef0f088205"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7f035547f390>"]},"metadata":{},"execution_count":45},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.scatter(y_valid_native[:,2], (y_valid_native[:,0]/y_valid_native[:,1]))\n","plt.scatter(pred_valid_native[:,2], (pred_valid_native[:,0]/pred_valid_native[:,1]))"]},{"cell_type":"markdown","metadata":{"id":"C5ouhkggE2i-"},"source":["Converting to Gold Stage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1BYVXwxAJBhD"},"outputs":[],"source":["conditions1 = [\n","              (((y_valid_native[:,0]/y_valid_native[:,1])) >.7),\n","              (y_valid_native[:,2] >= 80) & ((y_valid_native[:,0]/y_valid_native[:,1]) <=.7),\n","              (y_valid_native[:,2] < 80) & (y_valid_native[:,2] >= 50) & ((y_valid_native[:,0]/y_valid_native[:,1]) <=.7),\n","              (y_valid_native[:,2] < 60) & (y_valid_native[:,2] >= 40) & ((y_valid_native[:,0]/y_valid_native[:,1]) <=.7),\n","              (y_valid_native[:,2] < 40) & ((y_valid_native[:,0]/y_valid_native[:,1]) <=.7)\n","              ]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0riqEp6UQGiF","executionInfo":{"status":"ok","timestamp":1650550979292,"user_tz":420,"elapsed":338,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"d3a2f834-fe7b-4430-d2bc-a31ef75330ef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["189"]},"metadata":{},"execution_count":47}],"source":["sum((y_valid_native[:,2] <= 80) & (y_valid_native[:,2] >= 50) & ((y_valid_native[:,0]/y_valid_native[:,1]) <=.7))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RK6kyFm1JbU7"},"outputs":[],"source":["gold_stage = ['0','1', '2', '3', '4']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5i049dxMJ9cy"},"outputs":[],"source":["y_valid_stage = np.select(conditions1, gold_stage, default = np.nan)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYerCtw6QElT","executionInfo":{"status":"ok","timestamp":1650550981911,"user_tz":420,"elapsed":12,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"cb964f10-f514-4256-edf7-b9db6948d8d6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(946,)"]},"metadata":{},"execution_count":50}],"source":["y_valid_stage.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fXDr9P906oQX"},"outputs":[],"source":["conditions2 = [\n","              (((pred_valid_native[:,0]/pred_valid_native[:,1])) >.7),\n","              (pred_valid_native[:,2] > 80) & ((pred_valid_native[:,0]/pred_valid_native[:,1]) <=.7),\n","              (pred_valid_native[:,2] <= 80) & (pred_valid_native[:,2] >= 50) & ((pred_valid_native[:,0]/pred_valid_native[:,1]) <=.7),\n","              (pred_valid_native[:,2] <= 50) & (pred_valid_native[:,2] >= 30) & ((pred_valid_native[:,0]/pred_valid_native[:,1]) <=.7),\n","              (pred_valid_native[:,2] < 30) & ((pred_valid_native[:,0]/pred_valid_native[:,1]) <=.7)\n","              ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbUqaoKcSp4n"},"outputs":[],"source":["pred_valid_stage = np.select(conditions2, gold_stage, default = np.nan)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXivuzrUTo0q"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qrAqp6Q1T8Hq"},"outputs":[],"source":["results = confusion_matrix(y_valid_stage,pred_valid_stage)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1650550988396,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"dc2ZLW0HUAVl","outputId":"99a76217-26d0-42f0-80e0-7eae4d98dd04"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[465  21  38   2   0]\n"," [ 35  19  27   0   0]\n"," [ 49  14  94  31   0]\n"," [  5   0  19  22   2]\n"," [  1   0  13  57  32]]\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"executionInfo":{"elapsed":776,"status":"ok","timestamp":1650550990837,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"CQivGJkkVDs8","outputId":"31176041-4d87-418b-c186-873c7c7284e2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","ax = sns.heatmap(results, annot=True, cmap='Reds')\n","\n","ax.set_title('Gold Stage Prediction');\n","ax.set_xlabel('\\nPredicted Gold Stage')\n","ax.set_ylabel('Actual Gold Stage ');\n","\n","## Gold Stage labels \n","ax.xaxis.set_ticklabels(['0','1','2','3','4'])\n","ax.yaxis.set_ticklabels(['0','1','2','3','4'])\n","\n","## Display the visualization of the Confusion Matrix.\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"pw91RXkPs22l"},"source":["Pull the individual patient and look at the curves and see if there's an identifiable pattern. If they look healthy based on the curve.  there maybe subtle features in the image themselves that indicate otherwise. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":299,"status":"ok","timestamp":1650550994747,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"UdYD1TFz5mDt","outputId":"ed0e5c7e-4127-4f23-e1ef-f847e379eab2"},"outputs":[{"output_type":"stream","name":"stdout","text":["555\n","526\n","54\n","81\n","191\n","189\n","106\n"]}],"source":["#Sanity Check\n","#Gold Stage 0 Predict\n","print(sum((pred_valid_native[:,0]/pred_valid_native[:,1]) >.7))\n","#Gold Stage 0 Valid\n","print(sum((y_valid_native[:,0]/y_valid_native[:,1]) >.7))\n","#Gold Stage 1 Predict\n","print(sum((pred_valid_native[:,2] >= 80) & ((pred_valid_native[:,0]/pred_valid_native[:,1]) <=.7)))\n","#Gold Stage 1 Valid\n","print(sum((y_valid_native[:,2] >= 80) & ((y_valid_native[:,0]/y_valid_native[:,1]) <=.7)))\n","#Gold Stage 2 Predict\n","print(sum((pred_valid_native[:,2] <= 80) & (pred_valid_native[:,2] >= 50) & ((pred_valid_native[:,0]/pred_valid_native[:,1]) <.7)))\n","#Gold Stage 2 Valid\n","print(sum((y_valid_native[:,2] <= 80) & (y_valid_native[:,2] >= 50) & ((y_valid_native[:,0]/y_valid_native[:,1]) <=.7)))\n","#Gold Stage 3 Predict\n","(sum((pred_valid_native[:,2] < 60) & (pred_valid_native[:,2] >= 40) & ((pred_valid_native[:,0]/pred_valid_native[:,1]) <.7)))\n","#Gold Stage 3 Valid\n","print(sum((y_valid_native[:,2] < 60) & (y_valid_native[:,2] >= 40) & ((y_valid_native[:,0]/y_valid_native[:,1]) <.7)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"heNjQvIknRB7"},"outputs":[],"source":["from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import f1_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1650550997741,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"ENzPJKXqnPTg","outputId":"546bc9a7-2c88-4fa5-ff12-788d9652b343"},"outputs":[{"output_type":"stream","name":"stdout","text":["Recall: 0.478\n"]}],"source":["recall = recall_score(y_valid_stage,pred_valid_stage, average='macro')\n","print('Recall: %.3f' % recall)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1650550999665,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"29JuH2KIoX-U","outputId":"d2db9169-8ace-47a7-85e1-56f31aa36526"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.564\n"]}],"source":["precision = precision_score(y_valid_stage,pred_valid_stage, average='macro')\n","print('Precision: %.3f' % precision)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1650551001148,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"n7Rd0PPqpLEQ","outputId":"143b98db-deca-4bbe-ce98-75f16b9e175a"},"outputs":[{"output_type":"stream","name":"stdout","text":["F-Measure: 0.476\n"]}],"source":["score = f1_score(y_valid_stage,pred_valid_stage, average='macro')\n","print('F-Measure: %.3f' % score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Xpyzq4uUGU_"},"outputs":[],"source":["def accuracy(confusion_matrix):\n","    diagonal_sum = confusion_matrix.trace()\n","    sum_of_all_elements = confusion_matrix.sum()\n","    return diagonal_sum / sum_of_all_elements "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1650551005052,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"RzZtNQA3UL3x","outputId":"22e21249-7e59-49c8-ecf1-483e091e12a6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6680761099365751"]},"metadata":{},"execution_count":63}],"source":["accuracy(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1BkwpFeXrVcO"},"outputs":[],"source":["#Gold Stage 0 and 1\n","GS_0 = np.sum(results[0,0:2]) \n","#Gold stage 0 and 1 and 2\n","GS_1 = np.sum(results[1,0:3])\n","#Gold Stage 1 and 2 and 3\n","GS_2 = np.sum(results[2,1:4])\n","#Gold Stage 2 and 3 and 4\n","GS_3 = np.sum(results[3,2:5])\n","#Gold stage 3 and 4\n","GS_4 = np.sum(results[4,3:5])\n","#Total\n","total_pred= GS_0+GS_1+ GS_2+GS_3+GS_4\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1650551009110,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"4XadaOBtsO6Q","outputId":"401f5733-6c40-4d42-ed88-60a8ba3c6c1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8858350951374208\n"]}],"source":["#accuracy within +- one gold stage \n","accuracy = total_pred/results.sum()\n","print(accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650551010894,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"zEkpIw2wmP94","outputId":"bd4e58fb-5180-483a-f136-aac687abf8d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[465  21]\n","[35 19 27]\n","[14 94 31]\n","[19 22  2]\n","[57 32]\n"]}],"source":["print(results[0, 0:2])\n","print(results[1,0:3])\n","print(results[2,1:4])\n","print(results[3,2:5])\n","print(results[4,3:5])"]},{"cell_type":"markdown","metadata":{"id":"FMAJzrKH23Y_"},"source":["Next steps: Binary gold stage comparing 0 gold stage to the rest summarize accuracy of gold 0 than not, convert gold stage 0 as a no 1,2,3,4, is yes. 89% vs not in another paper, we can do better. \n","\n","INcorporating demographics "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356,"status":"ok","timestamp":1650551014328,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"tRGtZi0u3X5G","outputId":"88a13e84-0a58-4e81-e899-c27196eac629"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[465  21  38   2   0]\n"," [ 35  19  27   0   0]\n"," [ 49  14  94  31   0]\n"," [  5   0  19  22   2]\n"," [  1   0  13  57  32]]\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1650551016790,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"y8XDuwZL3uLX","outputId":"6d42a153-27f0-4890-f726-89fb33206fb8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["465"]},"metadata":{},"execution_count":68}],"source":["results[0,0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1650551018703,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"Y9_dMZIm3GS0","outputId":"c78e0f53-33ee-463e-af62-221431b1121a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8403805496828752"]},"metadata":{},"execution_count":69}],"source":["#Comparison of binary gold stage 0 to total\n","(np.sum(results[1:5,1:5]) + results[0,0]) / np.sum(results)\n","#confusing gold zeros rather than others gold zero patient and gold 1 patient make look similar, classified zero or one vs two to four"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":246,"status":"ok","timestamp":1650551021072,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"MskajP0QmeI3","outputId":"768f0294-b9b4-4fa9-8c69-2cb042d193de"},"outputs":[{"output_type":"stream","name":"stdout","text":["19\n"]}],"source":["np.sum(results[1:5, 0:1])\n","print(results[1,1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":467,"status":"ok","timestamp":1650551190085,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"kUFTLJ5sjpi-","outputId":"340caa06-dee9-47dc-d026-e3d28fdb2b78"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8773784355179705"]},"metadata":{},"execution_count":75}],"source":["#Comparison binary of gold 1 vs not\n","(np.sum(results[2:5, 0:1]) + np.sum(results[0:1, 2:5]) + np.sum(results[2:5,2:5]) + results[0,0] + results[1,1]) / np.sum(results)"]},{"cell_type":"code","source":["results[2:5, 0:1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"owmaVcHzgpxT","executionInfo":{"status":"ok","timestamp":1650551072654,"user_tz":420,"elapsed":442,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"}},"outputId":"3a3cd559-9e6f-4718-bc37-d549d0d4236b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[49],\n","       [ 5],\n","       [ 1]])"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":138,"status":"ok","timestamp":1649964961518,"user":{"displayName":"Brian Pak","userId":"12659659653829272834"},"user_tz":420},"id":"adIE5yZhj8n_","outputId":"509f7e24-d332-4334-e226-b100398448e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["946\n"]}],"source":["print(np.sum(results))"]},{"cell_type":"markdown","metadata":{"id":"DCHdJ-iUlN-W"},"source":[":create a notebook and only put relevant stuff that you need\n","\n","Look into binary gold stage becuase it should be higher.\n","\n","Confusing classifcation of gold 1 those that are, gold 0 v.s. not and gold 1 vs not\n","\n","shapley value, perturbation approach to determine, based on game theory and can be used to evaluate neural networks \n","variable importance measure of random forrest"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1jqkTzcB_s1SaZXFMw-_rLn8OMFbUJNVT","timestamp":1644602926914},{"file_id":"1hFxwGEwusjk_nyM3Lj0_iTge6sDOlDRj","timestamp":1644548555821},{"file_id":"1jD1s5NZYwQ7t8lbifPWbHDqQCmtO6XuK","timestamp":1643990434435}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}